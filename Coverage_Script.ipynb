{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Coverage Report Generation V9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import imp\n",
    "#imp.reload(utilsc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Variables to modify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "auth_path = r\".\\credentials.json\"\n",
    "auth_path = auth_path.replace(\"\\\\\",\"/\")\n",
    "\n",
    "with open(auth_path) as json_file:\n",
    "    json_credentials = json.load(json_file)\n",
    "    json_file.close()\n",
    "\n",
    "user = json_credentials[\"cisco_tableau\"][\"user\"]    # Your Cisco e-mail address\n",
    "cr_tableau_template_name = json_credentials[\"paths\"][\"tableau_template_cover_path\"] # twb template name/path\n",
    "personal_access_token_name = json_credentials[\"cisco_tableau\"][\"access_token_name\"]\n",
    "personal_access_token_secret = json_credentials[\"cisco_tableau\"][\"token\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Libraries & Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# ----------------------------------------- LIBRARIES\n",
    "\n",
    "#!pip install snowflake-connector-python\n",
    "#!pip install tableauhyperapi\n",
    "#!pip install tableau-api-lib\n",
    "#!pip install tableauserverclient\n",
    "#######!pip install hyperapi\n",
    "#!pip install fastparquet\n",
    "\n",
    "import os\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools\n",
    "import shutil\n",
    "import xml.etree.ElementTree as ET\n",
    "import snowflake.connector\n",
    "import re\n",
    "import webbrowser\n",
    "\n",
    "from zipfile import ZipFile\n",
    "import tableauserverclient as TSC\n",
    "from tableauhyperapi import *\n",
    "\n",
    "import smartsheet_lib as smartsheet\n",
    "import utils_coverage as utilsc\n",
    "\n",
    "# ----------------------------------------- FUNCTIONS\n",
    "\n",
    "qs = {8:1,9:1,10:1,11:2,12:2,1:2,2:3,3:3,4:3,5:4,6:4,7:4}\n",
    "fy = {1:1,2:1,3:0,4:0}\n",
    "\n",
    "class bcolors:\n",
    "    HEADER = '\\033[95m'\n",
    "    OKBLUE = '\\033[94m'\n",
    "    OKCYAN = '\\033[96m'\n",
    "    OKGREEN = '\\033[92m'\n",
    "    WARNING = '\\033[93m'\n",
    "    FAIL = '\\033[91m'\n",
    "    ENDC = '\\033[0m'\n",
    "    BOLD = '\\033[1m'\n",
    "    UNDERLINE = '\\033[4m'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Generating the Workbooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "current_path = os.getcwd().replace(\"\\\\\",\"/\")\n",
    "\n",
    "date = datetime.datetime.today()\n",
    "date = date.date()\n",
    "\n",
    "if date.weekday() in [0,1]:\n",
    "    delta_t = str(date-datetime.timedelta(4))\n",
    "else:\n",
    "    delta_t = str(date-datetime.timedelta(1))\n",
    "    \n",
    "month = datetime.datetime.today().strftime(\"%B\")\n",
    "\n",
    "print ('Current Path: ' + str(current_path))\n",
    "print ('Current Date: ' + str(date))\n",
    "\n",
    "# -----------------------------------------------------------------\n",
    "\n",
    "smartsheet_client = smartsheet.init_conn(\"J937aTx1hHKkv3ju15G0XGC0Qz6af50MNrhLq\")\n",
    "oa_sheet = smartsheet.load_sheet(3815245262153604,client=smartsheet_client,modified_since=delta_t)\n",
    "oa_df = pd.DataFrame()\n",
    "sheet_new = smartsheet.get_last_n_rows(oa_sheet,n_rows=4000)\n",
    "oa_df = smartsheet.sheet_to_df2(sheet_new,columns=oa_sheet.columns)\n",
    "oa_df = oa_df.query(\"`Request ID` != ''\")\n",
    "#oa_df['Request ID'] = oa_df['Request ID'].apply(lambda x:int(x)) # drop request id decimal places\n",
    "\n",
    "fields_df = utilsc.get_da_requests(da=user,df=oa_df)\n",
    "fields_df['CR Creation Date'] = date\n",
    "fields_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# Retrieving snowflake data and creating dataframes\n",
    "savs_list,gu_list,cav_list,cr_list = utilsc.get_ids_list(fields_df,separator=',') # IDs to look for on Snowflake\n",
    "print('1/7 - IDs created ...')\n",
    "uncovered_data = utilsc.get_uncovered_data2(user,ids_sav=savs_list,ids_gu=gu_list,ids_cr=cr_list,ids_cav=cav_list)  # Retrieve Uncovered Data from SF\n",
    "#uncovered_data = uncovered_data[uncovered_data['LINE_STATUS'].isin(['MISS ATTACH 1mo - 3mo','MISS ATTACH 3mo - 12mo' ])]\n",
    "print('2/7 - Uncovered data retrieved ...')\n",
    "appliance_data = utilsc.get_appliance_data(user,ids_sav=savs_list,ids_gu=gu_list,ids_cr=cr_list,ids_cav=cav_list)  # Retrieve Appliance Data from SF\n",
    "print('3/7 - Appliance data retrieved ...')\n",
    "coverage_data = utilsc.get_coverage_data(user,ids_sav=savs_list,ids_gu=gu_list,ids_cr=cr_list,ids_cav=cav_list) # Retrieve Coverage Data from SF\n",
    "print('4/7 - Coverage data retrieved ...')\n",
    "contracts_data = utilsc.get_contracts_data(user,ids_sav=savs_list,ids_gu=gu_list,ids_cr=cr_list,ids_cav=cav_list) # Retrieve Contracts Data from SF\n",
    "print('5/7 - Contracts data retrieved ...')\n",
    "tac_data = utilsc.get_tac_data(user,ids_sav=savs_list,ids_gu=gu_list,ids_cr=cr_list,ids_cav=cav_list) # Retrieve TAC data\n",
    "print('6/7 - TAC data retrieved ...')\n",
    "df_uncovered,df_coverage,df_contracts,df_appliance = utilsc.format_columns(uncovered_data,coverage_data,contracts_data,appliance_data)\n",
    "print('7/7 - Data gathering finished')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "sns_df = pd.DataFrame()\n",
    "folders_list = []\n",
    "smartsheet_fields = ['index','Request ID','Date Created',\n",
    "                         'Assigned DA','Campaign Name','Customer Name',\n",
    "                         'Input file URL','ID TYPE','SAV ID','CAV ID',\n",
    "                         'CAV BU ID','GU ID','Lvl1','Lvl2 (Region)',\n",
    "                         'Contract ID','Inventory Name','Appliance ID',\n",
    "                         'CR Party Name','CR Party ID','Comments','DA Comments',\n",
    "                         'Status','Requester Name','Who should be notified on completion of Analysis',\n",
    "                         'OP Status','CR Creation Date']\n",
    "\n",
    "#Empty list to store the Recommended Estimate for each account\n",
    "Recommended_Estimate_List = []\n",
    "Initial_Estimate_List = []\n",
    "\n",
    "for idx in range(len(fields_df)):\n",
    "    name = re.sub('[^A-Za-z0-9\\-]+', '', fields_df['Customer Name'][idx][0:15])\n",
    "    theater = fields_df['Lvl1'][idx]\n",
    "    req_type = fields_df['ID TYPE'][idx]\n",
    "    \n",
    "    if req_type == 'SAV ID':\n",
    "        ids = fields_df['sav_list'][idx]\n",
    "        id_type = 'SAV'\n",
    "    elif req_type == 'GU ID':\n",
    "        ids = fields_df['gu_list'][idx]\n",
    "        id_type = 'GU'\n",
    "    elif req_type == 'CR Party ID':\n",
    "        ids = fields_df['cr_list'][idx]\n",
    "        id_type = 'CR'\n",
    "    elif req_type == 'CAV ID':\n",
    "        ids = fields_df['cav_list'][idx]\n",
    "        id_type = 'CAV'   \n",
    "    \n",
    "    \n",
    "    req_id = str(int(fields_df['Request ID'][idx]))\n",
    "    date_created = fields_df['CR Creation Date'][idx]\n",
    "    print(f\"{idx+1}/{len(fields_df)}: {name}-{req_id}\",end=\" - \")\n",
    "    \n",
    "    folder =  f\"CR_{theater}_{req_id}_{name}_{req_type}_{str(date.year)}_{str(date.month)}_{str(date.day)}\" # folder name\n",
    "    folder_path = f\"{current_path}/CR/{month}/{date}/{folder}\"    \n",
    "    \n",
    "    uncovered_data_filtered = df_uncovered[df_uncovered['CUSTOMER_ID'].isin([int(customer_id) for customer_id in ids])]\n",
    "    uncovered_data_filtered = uncovered_data_filtered[uncovered_data_filtered['ACCOUNT_IDENTIFIER'] == id_type]\n",
    "    \n",
    "    appliance_data_filtered = df_appliance[df_appliance['CUSTOMER_ID'].isin([int(customer_id) for customer_id in ids])]\n",
    "    appliance_data_filtered = appliance_data_filtered[appliance_data_filtered['CUSTOMER_IDENTIFIER'] == id_type]   \n",
    "\n",
    "    #Function to Calculate the Recommended Estimate\n",
    "    Recommended_Estimate = utilsc.Total_Recommended_Estimate_CR(uncovered_data_filtered)\n",
    "    Recommended_Estimate_SSPT = utilsc.Total_Recommended_Estimate_CR(uncovered_data_filtered)\n",
    "    Initial_Estimate = utilsc.Total_Initial_Estimate(uncovered_data_filtered)\n",
    "    \n",
    "    \n",
    "    if len(uncovered_data_filtered) == 0:\n",
    "        print(bcolors.FAIL + f\"No Uncovered Data - No Serial Numbers to upload\" + bcolors.ENDC)\n",
    "        folders_list.append(\"N/A\")\n",
    "            \n",
    "    else:\n",
    "        \n",
    "        if Recommended_Estimate == 0 and Recommended_Estimate_SSPT == 0:\n",
    "            print(bcolors.FAIL + f\"No Uncovered Oppty - No Serial Numbers to upload\" + bcolors.ENDC)\n",
    "            folders_list.append(\"N/A\")\n",
    "        else:\n",
    "            \n",
    "            try:\n",
    "                os.makedirs(f\"{folder_path}/Data\")\n",
    "            except: pass    \n",
    "            folders_list.append(folder)\n",
    "\n",
    "            coverage_data_filtered = df_coverage[df_coverage['CUSTOMER_ID'].isin([int(customer_id) for customer_id in ids])]\n",
    "            coverage_data_filtered = coverage_data_filtered[coverage_data_filtered['ACCOUNT_IDENTIFIER'] == id_type]\n",
    "\n",
    "            contracts_data_filtered = df_contracts[df_contracts['Bk Sales Account Id Int'].isin([int(customer_id) for customer_id in ids])]\n",
    "            contracts_data_filtered = contracts_data_filtered[contracts_data_filtered['ACCOUNT_IDENTIFIER'] == id_type]\n",
    "\n",
    "            smartsheet_filtered = fields_df[smartsheet_fields].iloc[[idx]]\n",
    "\n",
    "            if id_type == 'CR':\n",
    "                tac_filtered = tac_data[tac_data['FLAG']=='GU']\n",
    "                tac_filtered = tac_data[tac_data['PARTY ID'].isin([int(customer_id) for customer_id in ids])]\n",
    "            else:\n",
    "                tac_filtered = tac_data[tac_data['FLAG']==id_type]\n",
    "                tac_filtered = tac_filtered[tac_filtered['ID'].isin([int(customer_id) for customer_id in ids])]\n",
    "\n",
    "            # Removing some columns\n",
    "            contracts_data_filtered.drop(['ACCOUNT_IDENTIFIER'],axis = 1,inplace = True)   \n",
    "\n",
    "            # Creating the extracts\n",
    "            uncovered_data_filtered.set_index('ACCOUNT_ID').to_csv(f\"{folder_path}/Data/uncovered.csv\")\n",
    "            appliance_data_filtered.set_index('APPLIANCE_ID').to_csv(f\"{folder_path}/Data/appliance_details.csv\")\n",
    "            coverage_data_filtered.set_index('CUSTOMER_ID').to_csv(f\"{folder_path}/Data/contracts-and-coverage.csv\")\n",
    "            contracts_data_filtered.set_index('Bk Sales Account Id Int').to_csv(f\"{folder_path}/Data/contract-view.csv\")\n",
    "            smartsheet_filtered.to_csv(f\"{folder_path}/Data/Smartsheet.csv\")\n",
    "            utilsc.create_extract(name='TAC',columns=utilsc.get_schema(table='TAC'),df=tac_filtered,path=folder_path)\n",
    "            \n",
    "            # -------------------------------------------------- Creating the workbooks twb\n",
    "            tree = ET.parse(cr_tableau_template_name)\n",
    "            for extract_path in tree.getroot().findall(\"./datasources/datasource/connection/named-connections/named-connection/connection[@class='textscan']\"):\n",
    "                extract_name = extract_path.attrib['directory']#.split('/')[-1]\n",
    "                extract_path.attrib['directory'] = f\"{folder_path}/Data\"\n",
    "\n",
    "            for extract_path in tree.getroot().findall(\"./datasources/datasource/connection/named-connections/named-connection/connection[@class='hyper']\"):\n",
    "                extract_name = extract_path.attrib['dbname'].split('/')[-1]\n",
    "                extract_path.attrib['dbname'] = f\"{folder_path}/Data/{extract_name}\"\n",
    "\n",
    "            ex_list = [\"6 - TAC.hyper\"]\n",
    "\n",
    "            for new_extract_path in tree.getroot().findall(\"./datasources/datasource/extract/connection[@class='hyper']\"):\n",
    "                new_extract_name = new_extract_path.attrib['dbname'].split('/')[-1]\n",
    "                if new_extract_name in ex_list:\n",
    "                    new_extract_path.attrib['dbname'] = f\"{folder_path}/Data/{new_extract_name}\"\n",
    "\n",
    "\n",
    "            try:\n",
    "                with open (f\"{folder_path}/{folder}.twb\", \"wb\") as files :                                             \n",
    "                    tree.write(files)\n",
    "\n",
    "                #utilsc.convert_to_twbx(f\"{folder_path}\")\n",
    "                print(\"twb created successfully\")\n",
    "\n",
    "                sn_df = uncovered_data_filtered[['SERIAL_NUMBER','CUSTOMER_ID','CUSTOMER_NAME','INSTANCE_NUMBER','LINE_STATUS','BK_PRODUCT_ID']]\n",
    "                sn_df['USER_ID'] = user\n",
    "                sn_df['SALES_LEVEL_1_NAME'] = theater\n",
    "                sn_df['SALES_LEVEL_2_NAME'] = fields_df['Lvl2 (Region)'][idx]\n",
    "                sn_df['COMPASS_REQ_ID'] = req_id\n",
    "                sn_df['COMPLETION_QUARTER'] = f\"FY{date_created.year + fy.get(qs.get(date_created.month))}Q{qs.get(date_created.month)}\"\n",
    "                sn_df['COMPLETION_DATE'] = date_created\n",
    "                sn_df[\"COMPLETION_DATE\"] = sn_df[\"COMPLETION_DATE\"].astype(str)\n",
    "                sn_df['ACCOUNT_IDENTIFIER'] = id_type\n",
    "                sn_df = sn_df[['USER_ID','SERIAL_NUMBER','CUSTOMER_ID','CUSTOMER_NAME','ACCOUNT_IDENTIFIER','SALES_LEVEL_1_NAME','SALES_LEVEL_2_NAME','COMPASS_REQ_ID','COMPLETION_QUARTER','COMPLETION_DATE','INSTANCE_NUMBER','LINE_STATUS','BK_PRODUCT_ID']]\n",
    "                print(f\" - {len(sn_df)} Serial Numbers to append\")\n",
    "                sns_df = pd.concat([sns_df,sn_df])                \n",
    "            except: print(bcolors.FAIL + \"Error\" + bcolors.ENDC)\n",
    "    \n",
    "    Recommended_Estimate_List.append(Recommended_Estimate)\n",
    "    Initial_Estimate_List.append(Initial_Estimate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Uploading URLs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "folders_id = {\n",
    "    \"US COMMERCIAL\": \"fd7772ee-058d-463a-bd0a-4f65542801a4\", # Americas\n",
    "    \"GLOBAL ENTERPRISE SEGMENT\": \"e57405f3-ca6c-4bc2-ad00-6e9e4eaddca3\",\n",
    "    \"LATIN AMERICA\": \"11411241-08ec-488e-b5e5-b858051464a5\",\n",
    "    \"CANADA\": \"2c7d703c-ccd7-4ebb-9a80-493efec42b37\",\n",
    "    \"AMERICAS_SP\": \"001fdd45-0e78-4c94-8529-f541a58903b0\",\n",
    "    \"US PS Market Segment\": \"bc2b9643-6dab-4659-967c-4c7faa1c9fbd\",\n",
    "    \"ANZ AREA\": \"dc644422-3a51-4940-9e0c-5b9eeba4e938\", # APJC\n",
    "    \"ASEAN_AREA\": \"486500cf-bab3-42f2-8cf6-912e0db03056\",\n",
    "    \"GREATER_CHINA\": \"48eaf322-742a-4b72-a750-fe87a18a3e46\",\n",
    "    \"INDIA_AREA\": \"3eda13f8-ce22-40fc-89e1-cca9f69318ee\",\n",
    "    \"JAPAN__\": \"18c5b29f-d451-4546-b924-0f9964d98c95\",\n",
    "    \"ROK_AREA\": \"0f98151c-0030-4f4b-90fc-a785b444cea1\",\n",
    "    \"APJ_SP\": \"517cddf4-032f-4dc0-9569-23ce801ebd33\",\n",
    "    \"EMEAR_GERMANY\": \"d11b1067-045d-42cb-a4c8-67805e4523a4\", # EMEAR\n",
    "    \"EMEAR_SP\": \"35a5ac5e-1654-421e-bb75-d8c95a9408e3\",\n",
    "    \"EMEAR-SOUTH\": \"7e91e72f-18bf-4b3b-8b72-7b964140743b\",\n",
    "    \"EMEAR-NORTH\": \"34b13798-5c47-4bcf-b3d1-917d802d511f\",\n",
    "    \"EMEAR-UKI\": \"268fdf46-d3ee-4623-ace9-97bb32ccc328\",\n",
    "    \"EMEAR_MEA\": \"95dcde09-a6fc-4fb1-b7a8-69e1dc4775e8\",\n",
    "    \"EMEAR-CENTRAL\": \"038970b3-8ea2-4a9a-86e8-6bd470350656\"\n",
    "}\n",
    "\n",
    "fields_df2 = fields_df.copy()\n",
    "fields_df2['folder_id'] = fields_df2['Lvl2 (Region)'].apply(lambda x : folders_id.get(x,''))\n",
    "#fields_df2['folder_id'] = '2fffed65-9c48-4ac3-9c96-21b9c2b8ca8f'\n",
    "fields_df2['project_name'] = folders_list\n",
    "fields_df2['project_url'] = fields_df2['project_name'].apply(lambda x: utilsc.get_url(x))\n",
    "fields_df2[['Customer Name','Lvl2 (Region)','folder_id','project_name','project_url']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# ---------------------------------------------------------\n",
    "\n",
    "import os\n",
    "import datetime\n",
    "\n",
    "from tableau_api_lib import TableauServerConnection\n",
    "from tableau_api_lib.utils import querying\n",
    "import time\n",
    "\n",
    "current_path = os.getcwd().replace(\"\\\\\",\"/\")\n",
    "\n",
    "#date = datetime.datetime.today()\n",
    "#date = date.date()\n",
    "\n",
    "month = datetime.datetime.today().strftime(\"%B\")\n",
    "\n",
    "config = {\n",
    "    \"tableau_server\": {\n",
    "        'server': 'https://cx-tableau-stage.cisco.com',\n",
    "        'api_version': '3.13',\n",
    "        'personal_access_token_name': personal_access_token_name,\n",
    "        'personal_access_token_secret': personal_access_token_secret,\n",
    "        'site_name': 'Compass',\n",
    "        'site_url': 'Compass'\n",
    "    }\n",
    "}\n",
    "\n",
    "conn = TableauServerConnection(config,env='tableau_server')\n",
    "\n",
    "for idx in range(len(fields_df2)):\n",
    "    conn.sign_in()\n",
    "    project = fields_df2['project_name'][idx]\n",
    "    \n",
    "    if project != \"N/A\":\n",
    "        name = fields_df2['Customer Name'][idx]\n",
    "\n",
    "    # -------------------------------------------------------------------    \n",
    "\n",
    "        try: \n",
    "\n",
    "            response = conn.publish_workbook(\n",
    "                project_id=fields_df2['folder_id'][idx],\n",
    "                workbook_file_path=f\"{current_path}/CR/{month}/{date}/{project}/{project}.twbx\",\n",
    "                #workbook_file_path=f\"{current_path}/CR/{month}/{date}/{project}.twbx\",\n",
    "                workbook_name=\"{}\".format(project),\n",
    "                #connection_username = user,\n",
    "                #connection_password =  \n",
    "                #embed_credentials_flag = True\n",
    "                #workbook_views_to_hide=['QA','Package Info'],\n",
    "                #hide_view_flag=True\n",
    "            )\n",
    "\n",
    "            if (response.status_code != 201):\n",
    "                print(bcolors.FAIL + bcolors.BOLD + f\"{idx+1}/{len(fields_df2)}:The {name} Coverage Report has an error and has not been published - {response.text}\"+bcolors.ENDC)\n",
    "                raise AssertionError()\n",
    "\n",
    "            else : print(f\"{idx+1}/{len(fields_df2)}:The {name} The Coverage Report has been published\")\n",
    "\n",
    "        except Exception as e: \n",
    "            print(bcolors.FAIL + bcolors.BOLD + str(e)+bcolors.ENDC)\n",
    "            pass\n",
    "\n",
    "        time.sleep(3)\n",
    "        conn.sign_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Print and Open CRs Links\n",
    "print(bcolors.UNDERLINE + \"-----------------------------COV URL--------------------------------\" + bcolors.ENDC)\n",
    "for link in fields_df2['project_url']:\n",
    "    if link != \"N/A\":\n",
    "        webbrowser.open(link)\n",
    "        print(link)\n",
    "    else:\n",
    "        print('N/A')\n",
    "\n",
    "#Print Recommended Estimate for each account\n",
    "print()\n",
    "print(bcolors.UNDERLINE + \"--------------------------COV OPPTY VALUE----------------------------\" + bcolors.ENDC)\n",
    "for Recommended_Estimate in Recommended_Estimate_List:\n",
    "    print(Recommended_Estimate, end = '' '\\n')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Print Initial Estimate for each account\n",
    "print()\n",
    "print(bcolors.UNDERLINE + \"--------------------------INITIAL ESTIMATE VALUE----------------------------\" + bcolors.ENDC)\n",
    "for Initial_Estimate in Initial_Estimate_List:\n",
    "    print(Initial_Estimate, end = '' '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RUN THIS CELL ONCE PER BATCH!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# Uploading Serial Numbers to Snowflake\n",
    "try:\n",
    "    utilsc.upload_data_to_sf(sns_df,user)\n",
    "    print(f\"{len(sns_df)} Serial Numbers uploaded\")\n",
    "except: print(bcolors.FAIL + \"Error\" + bcolors.ENDC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "188894ff957ed4c0bf1016ca99119c7aaf4eed608afb84d6dc1d383d4e0186dd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
