{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Get Id's from assigned requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install snowflake-connector-python\n",
    "#!pip install tableauhyperapi\n",
    "#!pip install tableau-api-lib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variables to modify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "auth_path = r\".\\credentials.json\"\n",
    "auth_path = auth_path.replace(\"\\\\\",\"/\")\n",
    "\n",
    "with open(auth_path) as json_file:\n",
    "    json_credentials = json.load(json_file)\n",
    "    json_file.close()\n",
    "\n",
    "user = json_credentials[\"cisco_tableau\"][\"user\"] # Your Cisco e-mail address\n",
    "tableau_template_name = json_credentials[\"paths\"][\"tableau_template_oe_path\"] #twb template name/path\n",
    "ib_file_name = 'IB.csv'\n",
    "coverage_file_name = 'Coverage.csv'\n",
    "sw_file_name = 'SW.csv'\n",
    "sntc_mapping_path = json_credentials[\"paths\"][\"sntc_mapping_path\"]\n",
    "personal_access_token_name = json_credentials[\"cisco_tableau\"][\"access_token_name\"]\n",
    "personal_access_token_secret = json_credentials[\"cisco_tableau\"][\"token\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting the accounts to work on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import datetime\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import shutil\n",
    "import itertools\n",
    "import xml.etree.ElementTree as ET\n",
    "import snowflake.connector\n",
    "import re\n",
    "import webbrowser\n",
    "import importlib\n",
    "import smartsheet_lib as smartsheet\n",
    "import utils_lib as utils\n",
    "import requests\n",
    "\n",
    "class bcolors:\n",
    "    HEADER = '\\033[95m'\n",
    "    OKBLUE = '\\033[94m'\n",
    "    OKCYAN = '\\033[96m'\n",
    "    OKGREEN = '\\033[92m'\n",
    "    WARNING = '\\033[93m'\n",
    "    FAIL = '\\033[91m'\n",
    "    ENDC = '\\033[0m'\n",
    "    BOLD = '\\033[1m'\n",
    "    UNDERLINE = '\\033[4m'\n",
    "    \n",
    "current_path = os.getcwd().replace(\"\\\\\",\"/\")\n",
    "\n",
    "date = datetime.datetime.today()\n",
    "date = date.date()\n",
    "\n",
    "if date.weekday() in [0,1]:\n",
    "    delta_t = str(date-datetime.timedelta(4))\n",
    "else:\n",
    "    delta_t = str(date-datetime.timedelta(1))\n",
    "    \n",
    "month = datetime.datetime.today().strftime(\"%B\")\n",
    "\n",
    "print ('Current Path: ' + str(current_path))\n",
    "print ('Current Date: ' + str(date))\n",
    "\n",
    "# -----------------------------------------------------------------\n",
    "\n",
    "\n",
    "smartsheet_client = smartsheet.init_conn(json_credentials[\"smartsheet\"][\"API_access_token\"])\n",
    "#oa_sheet = smartsheet.load_sheet(7190965472520068,client=smartsheet_client,modified_since=delta_t)  #Q3\n",
    "#oa_sheet = smartsheet.load_sheet(1763453217073028,client=smartsheet_client,modified_since=delta_t)  #Q4\n",
    "oa_sheet = smartsheet.load_sheet(3815245262153604,client=smartsheet_client,modified_since=delta_t)  #Q4-2\n",
    "oa_df = pd.DataFrame()\n",
    "sheet_new = smartsheet.get_last_n_rows(oa_sheet,n_rows=4000)\n",
    "oa_df = smartsheet.sheet_to_df2(sheet_new,columns=oa_sheet.columns)\n",
    "oa_df = oa_df.query(\"`Request ID` != ''\")\n",
    "oa_df['Request ID'] = oa_df['Request ID'].apply(lambda x:int(x)) # drop request id decimal places\n",
    "\n",
    "fields_df = utils.get_da_requests(da=user,df=oa_df)\n",
    "fields_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fields_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IDs list for CRBO queries (separator must be ';')\n",
    "savs_list,gu_list,cav_list,cr_list = utils.get_ids_list(fields_df,separator=';')\n",
    "cav_names = utils.get_cav_names(user,cav_list.replace(\";\",\",\"))\n",
    "print(f\"SAVs: {savs_list}\")\n",
    "print(f\"GUs: {gu_list}\")\n",
    "print(f\"CAVs: {cav_list}\")\n",
    "\n",
    "print(\"CAV NAMEs:\")\n",
    "for idx in cav_names[\"CAV NAME\"]:\n",
    "    if idx == cav_names[\"CAV NAME\"][len(cav_names[\"CAV NAME\"])-1]:\n",
    "        print(idx)\n",
    "    else:\n",
    "        print(idx,end=\";\")\n",
    "\n",
    "print(f\"CR Parties: {cr_list}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data from Snowflake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IDs list for Snowflake (separator must be ',')\n",
    "savs_list,gu_list,cav_list,cr_list = utils.get_ids_list(fields_df,separator=',')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Telemery dataframe from Snowflake (may take a few minutes)\n",
    "telemetry_df = pd.DataFrame()\n",
    "telemetry_df = utils.get_telemetry_df2(user,savs_list,gu_list,cr_list,cav_list)\n",
    "dna_df = utils.get_dna_df(user,savs_list,gu_list,cr_list,cav_list)\n",
    "print(f\"Telemetry data - Number of rows retrieved: {len(telemetry_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    #if len(dna_df) > 0:\n",
    "        #dna_df.to_csv(current_path + \"/dna_df.csv\",index=False)\n",
    "        #print(\"DNA file created successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TAC dataframe from Snowflake (may take a few minutes)\n",
    "tac_df = pd.DataFrame()\n",
    "tac_df_gu = pd.DataFrame()\n",
    "tac_df_cav = pd.DataFrame()\n",
    "tac_df_cr = pd.DataFrame()\n",
    "\n",
    "if 'SAV ID' in fields_df[\"ID TYPE\"].unique():\n",
    "    tac_df = utils.get_tac_df_new(user=user,ids=savs_list,id_type='SAV ID')\n",
    "    tac_df[\"BUG_CNT\"] = tac_df[\"BUG_CNT\"].replace(\"\",0.0)\n",
    "    print(f\"SAV TAC data - Number of rows retrieved: {len(tac_df)}\")\n",
    "if 'GU ID' in fields_df[\"ID TYPE\"].unique():\n",
    "    tac_df_gu = utils.get_tac_df_new(user=user,ids=gu_list,id_type='GU ID')\n",
    "    tac_df_gu[\"BUG_CNT\"] = tac_df_gu[\"BUG_CNT\"].replace(\"\",0.0)\n",
    "    print(f\"GU TAC data - Number of rows retrieved: {len(tac_df_gu)}\")\n",
    "if 'CAV ID' in fields_df[\"ID TYPE\"].unique():\n",
    "    tac_df_cav = utils.get_tac_df_new(user=user,ids=cav_list,id_type='CAV ID')\n",
    "    tac_df_cav[\"BUG_CNT\"] = tac_df_cav[\"BUG_CNT\"].replace(\"\",0.0)\n",
    "    print(f\"CAV TAC data - Number of rows retrieved: {len(tac_df_cav)}\")\n",
    "if 'CR Party ID' in fields_df[\"ID TYPE\"].unique():\n",
    "    tac_df_cr = utils.get_tac_df_new(user=user,ids=cr_list,id_type='PARTY ID')\n",
    "    tac_df_cr[\"BUG_CNT\"] = tac_df_cr[\"BUG_CNT\"].replace(\"\",0.0)\n",
    "    print(f\"CR TAC data - Number of rows retrieved: {len(tac_df_cr)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Package creation\n",
    "\n",
    "#### Note: Run the following lines only if you have already downloaded the data from CRBO and saved it in their respective SAV_ID/GU_ID folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------------------------------- Load SAV/GU files\n",
    "\n",
    "renewals_s = pd.DataFrame()\n",
    "coverage_s = pd.DataFrame()\n",
    "subs_s = pd.DataFrame()\n",
    "    \n",
    "renewals_g = pd.DataFrame()\n",
    "coverage_g = pd.DataFrame()\n",
    "subs_g = pd.DataFrame()\n",
    "\n",
    "renewals_c = pd.DataFrame()\n",
    "coverage_c = pd.DataFrame()\n",
    "subs_c = pd.DataFrame()\n",
    "    \n",
    "renewals_cr = pd.DataFrame()\n",
    "coverage_cr = pd.DataFrame()\n",
    "subs_cr = pd.DataFrame()\n",
    "\n",
    "sntc_mapping = pd.read_excel(sntc_mapping_path,sheet_name=\"Output\").fillna(0)\n",
    "\n",
    "if 'SAV ID' in fields_df[\"ID TYPE\"].unique():\n",
    "    for f in os.listdir(f\"{current_path}/CRBO/SAV_ID\"):\n",
    "        if f.__contains__(ib_file_name):\n",
    "            df_s = pd.read_csv(f\"{current_path}/CRBO/SAV_ID/{f}\", \n",
    "                                 dtype={'SAV ID':str,\n",
    "                                    'Instance Shipped Fiscal Year':str,\n",
    "                                    'Item Quantity':float,\n",
    "                                    'LDoS FY':str,\n",
    "                                    'Best Site ID':float,\n",
    "                                    'Contract Number':str,\n",
    "                                    'Service Brand Code':str})\n",
    "            df_s.insert(loc=2, column='Best Site ID', value=-9999)\n",
    "            df_s.insert(loc=3, column='Best Site Customer Name', value='UNKNOWN')\n",
    "            renewals_s = renewals_s.append(df_s)                             \n",
    "    coverage_s = pd.read_csv(f\"{current_path}/CRBO/SAV_ID/{coverage_file_name}\", dtype={'SAV ID':str})\n",
    "    subs_s = pd.read_csv(f\"{current_path}/CRBO/SAV_ID/{sw_file_name}\", dtype={'SAV ID':str})\n",
    "    print('SAV files loaded!')\n",
    "    print(len(renewals_s))\n",
    "    \n",
    "if 'GU ID' in fields_df[\"ID TYPE\"].unique():\n",
    "    for f in os.listdir(f\"{current_path}/CRBO/GU_ID\"):\n",
    "        if f.__contains__(ib_file_name):\n",
    "            df_g = pd.read_csv(f\"{current_path}/CRBO/GU_ID/{f}\", \n",
    "                                 dtype={'Best Site GU Party ID':str, \n",
    "                                        'Instance Shipped Fiscal Year':str,\n",
    "                                        'Item Quantity':float,\n",
    "                                        'LDoS FY':str,\n",
    "                                        'Service Brand Code':str})\n",
    "            df_g.insert(loc=2, column='Best Site ID', value=-9999.0)\n",
    "            df_g.insert(loc=3, column='Best Site Customer Name', value='UNKNOWN')\n",
    "            renewals_g = renewals_g.append(df_g)\n",
    "    coverage_g = pd.read_csv(f\"{current_path}/CRBO/GU_ID/{coverage_file_name}\", dtype={'Best Site GU Party ID':str})\n",
    "    subs_g = pd.read_csv(f\"{current_path}/CRBO/GU_ID/{sw_file_name}\", dtype={'GU Party ID':str})\n",
    "    print('GU files loaded!')\n",
    "    print(len(renewals_g))\n",
    "    \n",
    "if 'CAV ID' in fields_df[\"ID TYPE\"].unique():\n",
    "    for f in os.listdir(f\"{current_path}/CRBO/CAV_ID\"):\n",
    "        if f.__contains__(ib_file_name):\n",
    "            df_cav = pd.read_csv(f\"{current_path}/CRBO/CAV_ID/{f}\", \n",
    "                                 dtype={#'CX Customer ID':str, \n",
    "                                        'Instance Shipped Fiscal Year':str,\n",
    "                                        'Item Quantity':float,\n",
    "                                        'LDoS FY':str,\n",
    "                                        'Service Brand Code':str})\n",
    "            df_cav.insert(loc=1, column='Best Site ID', value=-9999)\n",
    "            df_cav.insert(loc=2, column='Best Site Customer Name', value='UNKNOWN')\n",
    "            renewals_c = renewals_c.append(df_cav)\n",
    "    coverage_c = pd.read_csv(f\"{current_path}/CRBO/CAV_ID/{coverage_file_name}\") #dtype={'CX Customer ID':str}\n",
    "    subs_c = pd.read_csv(f\"{current_path}/CRBO/CAV_ID/{sw_file_name}\") #dtype={'CX Customer ID':str}\n",
    "    print('CAV files loaded!')\n",
    "    print(len(renewals_c))\n",
    "    \n",
    "if 'CR Party ID' in fields_df[\"ID TYPE\"].unique():\n",
    "    for f in os.listdir(f\"{current_path}/CRBO/PARTY_ID\"):\n",
    "        if f.__contains__(ib_file_name):\n",
    "            df_cr = pd.read_csv(f\"{current_path}/CRBO/PARTY_ID/{f}\", \n",
    "                                 dtype={'Best Site CR Party ID':str, \n",
    "                                        'Instance Shipped Fiscal Year':str,\n",
    "                                        'Item Quantity':float,\n",
    "                                        'LDoS FY':str,\n",
    "                                        'Service Brand Code':str})\n",
    "            df_cr.insert(loc=2, column='Best Site ID', value=-9999)\n",
    "            df_cr.insert(loc=3, column='Best Site Customer Name', value='UNKNOWN')\n",
    "            renewals_cr = renewals_cr.append(df_cr)\n",
    "    coverage_cr = pd.read_csv(f\"{current_path}/CRBO/PARTY_ID/{coverage_file_name}\", dtype={'Best Site CR Party ID':str})\n",
    "    subs_cr = pd.read_csv(f\"{current_path}/CRBO/PARTY_ID/{sw_file_name}\", dtype={'CR Party ID':str})\n",
    "    print('CR files loaded!')\n",
    "    print(len(renewals_cr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "smartsheet_fields = ['index','Request ID','Date Created',\n",
    "                         'Assigned DA','Campaign Name','Customer Name',\n",
    "                         'Input file URL','ID TYPE','SAV ID','CAV ID',\n",
    "                         'CAV BU ID','GU ID','Lvl1','Lvl2 (Region)',\n",
    "                         'Contract ID','Inventory Name','Appliance ID',\n",
    "                         'CR Party Name','CR Party ID','Comments','DA Comments',\n",
    "                         'Status','Requester Name','Who should be notified on completion of Analysis',\n",
    "                         'OP Status']\n",
    "folders_list = []\n",
    "folders_path_list = []\n",
    "type_list = []\n",
    "sntc_oppty_list = []\n",
    "renewals = pd.DataFrame()\n",
    "coverage = pd.DataFrame()\n",
    "subs = pd.DataFrame()\n",
    "map_req_type = {'SAV ID':'SAV','GU ID':'GU','CR Party ID':'CR','CAV ID':'CAV'}\n",
    "\n",
    "# ------------------------------------------------------------------- Mapping Files\n",
    "\n",
    "local_path = \".\"\n",
    "\n",
    "contract_types_list = pd.read_excel(f\"{local_path}/Mapping files/1-Contract_Types_List.xlsx\", sheet_name='SNTCSolutionSupport')\n",
    "contract_types_list = contract_types_list.astype({'Contract Type':str},errors='raise')\n",
    "\n",
    "success_track_pricing_list = pd.read_excel(f\"{local_path}/Mapping files/2-Success_Track_Pricing_List.xlsx\", sheet_name='Success Track PIDs')\n",
    "success_track_pricing_list = success_track_pricing_list.astype({'Product SKU':str},errors='raise')\n",
    "\n",
    "sspt_pricing_list_eligibleSSPT = pd.read_excel(f\"{local_path}/Mapping files/3-SSPT_Princing_List.xlsx\", sheet_name='Eligible SSPT')\n",
    "sspt_pricing_list_eligibleSSPT = sspt_pricing_list_eligibleSSPT.astype({'Product SKU':str},errors='raise')\n",
    "\n",
    "sspt_pricing_list_outputTable = pd.read_excel(f\"{local_path}/Mapping files/3-SSPT_Princing_List.xlsx\", sheet_name='Output Table')\n",
    "sspt_pricing_list_outputTable = sspt_pricing_list_outputTable.astype({'Product SKU':str},errors='raise')\n",
    "\n",
    "sntc_pricing_list = pd.read_excel(f\"{local_path}/Mapping files/4-SNTC_Princing_List.xlsx\", sheet_name='Output')\n",
    "sntc_pricing_list = sntc_pricing_list.astype({'Product SKU ':str},errors='raise')\n",
    "\n",
    "htec_contract_types_htec = pd.read_excel(f\"{local_path}/Mapping files/6-HTEC_Contract_Types.xlsx\", sheet_name='HTEC')\n",
    "htec_contract_types_htec = htec_contract_types_htec.astype({'GSP':str},errors='raise')\n",
    "\n",
    "htec_contract_types_swss = pd.read_excel(f\"{local_path}/Mapping files/6-HTEC_Contract_Types.xlsx\", sheet_name='SWSS')\n",
    "htec_contract_types_swss = htec_contract_types_swss.astype({'GSP':str},errors='raise')\n",
    "\n",
    "combined_services = pd.read_excel(f\"{local_path}/Mapping files/8-Combined_Services.xlsx\", sheet_name='Sheet1')\n",
    "combined_services = combined_services.astype({'Combined Services Service Level':str},errors='raise')\n",
    "\n",
    "product_banding = pd.read_excel(f\"{local_path}/Mapping files/9-PRODUCT_BANDING.xlsx\", sheet_name='9-PRODUCT_BANDING')\n",
    "product_banding = product_banding.astype({'INTERNAL_BE_PRODUCT_FAMILY':str},errors='raise')\n",
    "\n",
    "expert_care_component_bands = pd.read_excel(f\"{local_path}/Mapping files/7-Expert_Care_Components_Bands.xlsx\")\n",
    "\n",
    "# ------------------------------------------------------------------- Lists for Q&A\n",
    "AC_NAME=[]\n",
    "AC_ID=[]\n",
    "IB_VALUE=[]\n",
    "IB_COV=[]\n",
    "MR=[]\n",
    "SSPTOPP=[]\n",
    "STOPP=[]\n",
    "EXC=[]\n",
    "SNT=[]\n",
    "SN_LEGHT = []\n",
    "ST_L2_LEGHT=[]\n",
    "PACKAGE_INFO=[]\n",
    "\n",
    "# ------------------------------------------------------------------- Accounts loop\n",
    "    \n",
    "for idx in range(len(fields_df)):\n",
    "    req_type = fields_df['ID TYPE'][idx]\n",
    "    name = re.sub('[^A-Za-z0-9\\-]+', '', fields_df['Customer Name'][idx][0:15])\n",
    "    theater = fields_df['Lvl1'][idx]\n",
    "    party_ids = fields_df['cr_list'][idx]\n",
    "    print(name)\n",
    "    \n",
    "    if req_type == 'SAV ID':\n",
    "        ids = fields_df['sav_list'][idx]\n",
    "        ids_smartsheet = [fields_df['SAV ID'][idx]]\n",
    "        ids_smartsheet2 = ids\n",
    "        print(ids)\n",
    "        id_field = 'SAV ID'\n",
    "        id_field_sw = 'SAV ID'\n",
    "        id_flag_tac = 'SAV'\n",
    "        renewals = renewals_s.copy()\n",
    "        coverage = coverage_s.copy()\n",
    "        subs = subs_s.copy()\n",
    "        tac = tac_df.copy()\n",
    "        id_field_tac = 'ID'\n",
    "        \n",
    "    elif req_type == 'GU ID':\n",
    "        ids = fields_df['gu_list'][idx]\n",
    "        ids_smartsheet = [fields_df['GU ID'][idx]]\n",
    "        ids_smartsheet2 = ids\n",
    "        print(ids)\n",
    "        id_field = 'Best Site GU Party ID'\n",
    "        id_field_sw = 'GU Party ID'\n",
    "        id_flag_tac = 'GU'\n",
    "        renewals = renewals_g.copy()\n",
    "        coverage = coverage_g.copy()\n",
    "        subs = subs_g.copy()\n",
    "        tac = tac_df_gu.copy()\n",
    "        id_field_tac = 'ID'\n",
    "        \n",
    "    elif req_type == 'CAV ID':\n",
    "        cav_names[\"CAV ID\"] = cav_names[\"CAV ID\"].astype(str)\n",
    "        cav_name_id = pd.DataFrame(data = {\"CAV ID\":fields_df[[\"cav_list\"]].iloc[idx,0]}).merge(cav_names,how=\"innef\")[\"CAV NAME\"].to_list()\n",
    "        ids = cav_name_id\n",
    "        ids_smartsheet = [fields_df[\"CAV ID\"][idx]]\n",
    "        ids_smartsheet2 = fields_df['cav_list'][idx]\n",
    "        print(ids)\n",
    "        id_field = 'CAV - Account Name'\n",
    "        id_field_sw = 'CAV -  Account Name'\n",
    "        id_flag_tac = 'CAV'\n",
    "        renewals = renewals_c.copy()\n",
    "        coverage = coverage_c.copy()\n",
    "        subs = subs_c.copy()\n",
    "        tac = tac_df_cav.copy()\n",
    "        id_field_tac = 'ID'\n",
    "        \n",
    "    elif req_type == 'CR Party ID':\n",
    "        ids = fields_df['cr_list'][idx]\n",
    "        ids_smartsheet = [fields_df['CR Party ID'][idx]]\n",
    "        ids_smartsheet2 = ids\n",
    "        print(ids)\n",
    "        id_field = 'Best Site CR Party ID'\n",
    "        id_field_sw = 'CR Party ID'\n",
    "        id_flag_tac = 'GU'\n",
    "        renewals = renewals_cr.copy()\n",
    "        coverage = coverage_cr.copy()\n",
    "        subs = subs_cr.copy()\n",
    "        tac = tac_df_cr.copy()\n",
    "        id_field_tac = 'PARTY ID'\n",
    "    \n",
    "    if req_type == \"CAV ID\":\n",
    "        req_id = fields_df['CAV ID'][idx][0:6]\n",
    "    else:\n",
    "        req_id = ids[0]\n",
    "    \n",
    "    # ---------------------------------------------------------------------- Folders creation\n",
    "\n",
    "    folder =  f\"OP_{theater}_{req_type}_{req_id}_{name}_{str(date.year)}_{str(date.month)}_{str(date.day)}\" # folder name\n",
    "    folder_path = f\"{current_path}/OP/{month}/{date}/{folder}\"\n",
    "    \n",
    "    try:\n",
    "        os.makedirs(f\"{folder_path}/Data\")\n",
    "        os.makedirs(f\"{folder_path}/Extracts\")\n",
    "        \n",
    "    except: pass    \n",
    "    \n",
    "    folders_list.append(folder)\n",
    "    folders_path_list.append(f'{folder_path}/{folder}.twb')\n",
    "    \n",
    "    # --------------------------------------------------------------------- Data transform and filtering\n",
    "    \n",
    "    smartsheet_filtered = fields_df[smartsheet_fields].iloc[[idx]]\n",
    "    smartsheet_filtered = smartsheet_filtered.rename(columns={\"Who should be notified on completion of Analysis\":\"Parties Active Collectors\"})\n",
    "    renew_filtered = renewals.query(\"`{}` in {}\".format(id_field,ids))\n",
    "    coverage_filtered  = coverage.query(\"`{}` in {}\".format(id_field,ids))\n",
    "    subs_filtered  = subs.query(\"`{}` in {}\".format(id_field_sw,ids))\n",
    "    \n",
    "    if req_type == 'CAV ID':\n",
    "        renew_filtered = cav_names.merge(renew_filtered,how=\"right\",left_on=\"CAV NAME\",right_on = \"CAV - Account Name\").drop(columns=\"CAV NAME\")\n",
    "        renew_filtered[\"CAV ID\"] = renew_filtered[\"CAV ID\"].astype(int)\n",
    "        renew_filtered[\"Item Quantity\"] = renew_filtered[\"Item Quantity\"].astype(float)\n",
    "        coverage_filtered = cav_names.merge(coverage_filtered,how=\"right\",left_on=\"CAV NAME\",right_on = \"CAV - Account Name\").drop(columns=\"CAV NAME\")\n",
    "        subs_filtered = cav_names.merge(subs_filtered,how=\"right\",left_on=\"CAV NAME\",right_on = \"CAV -  Account Name\").drop(columns=\"CAV NAME\")\n",
    "        \n",
    "        \n",
    "    dna_filtered = dna_df[dna_df['CUSTOMER_ID'].isin([int(ids) for ids in ids_smartsheet2])]\n",
    "    dna_filtered = dna_filtered[dna_filtered['ACCOUNT_INDENTIFIER']==map_req_type.get(req_type)]\n",
    "    \n",
    "    telemetry_filtered = telemetry_df[telemetry_df['ID'].isin([int(ids) for ids in ids_smartsheet2])]\n",
    "    telemetry_filtered = telemetry_filtered[telemetry_filtered['ACCOUNT_ID']==map_req_type.get(req_type)]\n",
    "    parties_active_collectors = telemetry_filtered[\"Party ID\"].unique().astype(str).tolist()\n",
    "    parties_active_collectors = \",\".join(parties_active_collectors)                                         \n",
    "    \n",
    "    smartsheet_filtered[\"Parties Active Collectors\"][idx] = parties_active_collectors\n",
    "    #telemetry_filtered = telemetry_df.query(\"`{}` in {}\".format('Party ID',[int(i) for i in party_ids if i != '']))\n",
    "    sntc_oppty_list.append(utils.SNTC_Oppty(renew_filtered,sntc_mapping))\n",
    "    \n",
    "    if req_type == 'CAV ID':\n",
    "        ids = fields_df['cav_list'][idx]\n",
    "    \n",
    "    tac_filtered = tac.query(\"(`{}` in {}) and (FLAG == '{}')\".format(id_field_tac,[int(i) for i in ids],id_flag_tac)) # id in TAC must be integer, not str\n",
    "        \n",
    "    print(len(renew_filtered))\n",
    "    \n",
    "    #renew_filtered.to_csv(f\"{folder_path}/Data/IB/IB.csv\",index=False)\n",
    "    #coverage_filtered.to_csv(f\"{folder_path}/Data/Coverage.csv\",index=False)\n",
    "    #subs_filtered.to_csv(f\"{folder_path}/Data/SW.csv\",index=False)\n",
    "    dna_filtered.to_csv(f\"{folder_path}/Data/DNA.csv\",index=False)\n",
    "        \n",
    "    renew_filtered = utils.fill_nas(renew_filtered)\n",
    "    coverage_filtered = utils.fill_nas(coverage_filtered)\n",
    "    subs_filtered = utils.fill_nas(subs_filtered)\n",
    "    \n",
    "    if req_type == 'SAV ID':\n",
    "        renew_filtered[['SAV ID','LDoS FY','Instance Shipped Fiscal Year','Contract Number']] = renew_filtered[['SAV ID','LDoS FY','Instance Shipped Fiscal Year','Contract Number']].fillna(0).apply(pd.to_numeric, downcast='integer')\n",
    "    elif req_type == 'GU ID':\n",
    "        renew_filtered[['Best Site GU Party ID','LDoS FY','Instance Shipped Fiscal Year','Contract Number']] = renew_filtered[['Best Site GU Party ID','LDoS FY','Instance Shipped Fiscal Year','Contract Number']].fillna(0).apply(pd.to_numeric, downcast='integer')\n",
    "    elif req_type == 'CAV ID':\n",
    "        #renew_filtered[['CX Customer ID','LDoS FY','Instance Shipped Fiscal Year','Contract Number']] = renew_filtered[['CX Customer ID','LDoS FY','Instance Shipped Fiscal Year','Contract Number']].fillna(0).apply(pd.to_numeric, downcast='integer')\n",
    "        renew_filtered[['CAV ID','LDoS FY','Instance Shipped Fiscal Year','Contract Number']] = renew_filtered[['CAV ID','LDoS FY','Instance Shipped Fiscal Year','Contract Number']].fillna(0).apply(pd.to_numeric, downcast='integer')\n",
    "    elif req_type == 'CR Party ID':\n",
    "        renew_filtered[['Best Site CR Party ID','LDoS FY','Instance Shipped Fiscal Year','Contract Number']] = renew_filtered[['Best Site CR Party ID','LDoS FY','Instance Shipped Fiscal Year','Contract Number']].fillna(0).apply(pd.to_numeric, downcast='integer')\n",
    "   \n",
    "    renew_filtered['LDoS'] = pd.to_datetime(renew_filtered['LDoS'], errors='coerce').replace({pd.NaT:None})\n",
    "    subs_filtered[['Contract Term End Quarter']] = subs_filtered[['Contract Term End Quarter']].fillna(0).apply(pd.to_numeric, downcast='integer')\n",
    "    renew_filtered['Item Quantity'] = renew_filtered['Item Quantity'].astype(float)\n",
    "    coverage_filtered['Item Quantity'] = coverage_filtered['Item Quantity'].astype(int)\n",
    "    \n",
    "    # --------------------------------------------------------------------- Template xml set up\n",
    "\n",
    "    tree = ET.parse(tableau_template_name)\n",
    "    \n",
    "    for extract_path in tree.getroot().findall(\"./datasources/datasource/connection/named-connections/named-connection/connection[@class='textscan']\"):\n",
    "        #extract_name = extract_path.attrib['directory'].split('/')[-1]\n",
    "        extract_path.attrib['directory'] = f\"{folder_path}/Data\"\n",
    "    \n",
    "    for extract_path in tree.getroot().findall(\"./datasources/datasource/connection/named-connections/named-connection/connection[@class='hyper']\"):\n",
    "        extract_name = extract_path.attrib['dbname'].split('/')[-1]\n",
    "        extract_path.attrib['dbname'] = f\"{folder_path}/Extracts/{extract_name}\"\n",
    "    \n",
    "    with open (f\"{folder_path}/{folder}.twb\", \"wb\") as files :                                             \n",
    "        tree.write(files)\n",
    "        \n",
    "    # --------------------------------------------------------------------- Package type\n",
    "        \n",
    "    if len(renew_filtered) > 0:\n",
    "        if len(telemetry_filtered) == 0:\n",
    "            type_list.append('Lite')\n",
    "        else:\n",
    "            type_list.append('Prime')\n",
    "    elif len(renew_filtered) == 0:\n",
    "        type_list.append('No Report')\n",
    "    \n",
    "    # --------------------------------------------------------------------- Extracts creation\n",
    "\n",
    "    utils.create_extract(name='Smartsheet',columns=utils.get_schema(table='smartsheet',id_type=req_type),df=smartsheet_filtered,path=folder_path)\n",
    "    #utils.create_extract(name='IB',columns=utils.get_schema(table='ib',id_type=req_type),df=renew_filtered,path=folder_path)\n",
    "    #utils.create_extract(name='Coverage',columns=utils.get_schema(table='coverage',id_type=req_type),df=coverage_filtered,path=folder_path)\n",
    "    #utils.create_extract(name='SW',columns=utils.get_schema(table='sw',id_type=req_type),df=subs_filtered,path=folder_path)\n",
    "    #utils.create_extract(name='TAC',columns=utils.get_schema(table='tac2',id_type=req_type),df=tac_filtered,path=folder_path)    \n",
    "    #utils.create_extract(name='CIR',columns=utils.get_schema(table='cir',id_type=req_type),df=telemetry_filtered.drop(columns=['ACCOUNT_ID','ID']),path=folder_path)\n",
    "\n",
    "\n",
    "    # --------------------------------------------------------------------- CSV creation for Tableau\n",
    "    ### ---------------------------------------  Install Base merge \n",
    "\n",
    "    renew_filtered = utils.set_datasource(renew_filtered,'ib',f\"{folder_path}/Data/1-Installed Base (2).csv\",contract_types_list,\n",
    "                    success_track_pricing_list,sspt_pricing_list_eligibleSSPT,\n",
    "                    sspt_pricing_list_outputTable,sntc_pricing_list,htec_contract_types_htec,\n",
    "                    htec_contract_types_swss,combined_services,product_banding)\n",
    "\n",
    "    ### ---------------------------------------  SNTC Collector\n",
    "    telemetry_filtered = utils.set_datasource(telemetry_filtered,'cir',f\"{folder_path}/Data/3-SNTC Collector (2).csv\",contract_types_list,\n",
    "                    success_track_pricing_list,sspt_pricing_list_eligibleSSPT,\n",
    "                    sspt_pricing_list_outputTable,sntc_pricing_list,htec_contract_types_htec,\n",
    "                    htec_contract_types_swss,combined_services,product_banding)\n",
    "\n",
    "    ### ---------------------------------------  Coverage\n",
    "    coverage_filtered = utils.set_datasource(coverage_filtered,'coverage',f\"{folder_path}/Data/Coverage.csv\",contract_types_list,\n",
    "                    success_track_pricing_list,sspt_pricing_list_eligibleSSPT,\n",
    "                    sspt_pricing_list_outputTable,sntc_pricing_list,htec_contract_types_htec,\n",
    "                    htec_contract_types_swss,combined_services,product_banding)\n",
    "\n",
    "\n",
    "    ### ---------------------------------------  SW\n",
    "    subs_filtered = utils.set_datasource(subs_filtered,'sw',f\"{folder_path}/Data/SW.csv\",contract_types_list,\n",
    "                    success_track_pricing_list,sspt_pricing_list_eligibleSSPT,\n",
    "                    sspt_pricing_list_outputTable,sntc_pricing_list,htec_contract_types_htec,\n",
    "                    htec_contract_types_swss,combined_services,product_banding)\n",
    "\n",
    "    ### ---------------------------------------  TAC\n",
    "    tac_filtered = utils.set_datasource(tac_filtered,'tac',f\"{folder_path}/Data/6-TAC.csv\",contract_types_list,\n",
    "                    success_track_pricing_list,sspt_pricing_list_eligibleSSPT,\n",
    "                    sspt_pricing_list_outputTable,sntc_pricing_list,htec_contract_types_htec,\n",
    "                    htec_contract_types_swss,combined_services,product_banding)\n",
    "\n",
    "    ## ---------------------------------------  Expert Care\n",
    "\n",
    "    expert_care_component_bands.to_csv(f\"{folder_path}/Data/7-Expert_Care_Components_Bands.csv\", index=False)\n",
    "\n",
    "    # --------------------------------------------------------------------- Calculating Q&A values\n",
    "\n",
    "    ib_value = utils.ib_value_validation(utils.IB_attributes(renew_filtered))\n",
    "    ib_covered = utils.ib_covered_validation(utils.IB_attributes(renew_filtered))\n",
    "    mayor_rw = utils.rw_validation(utils.IB_attributes(renew_filtered))\n",
    "    sspt_opp = utils.oppty_validation(utils.SSPT_Oppty(renew_filtered))\n",
    "    st_opp = utils.oppty_validation(utils.ST_Oppty(renew_filtered))\n",
    "    exp_care = utils.oppty_validation(utils.expert_care_verification(expert_care_component_bands))\n",
    "    sntc_val = utils.oppty_validation(utils.smartnet_verification(renew_filtered))\n",
    "    snl = utils.lenght_validation(utils.smartnet_total_care_NBD_list_price(renew_filtered)[1])\n",
    "    stl = utils.lenght_validation(utils.estimated_list_price(renew_filtered)[1])\n",
    "    smart_sheet = fields_df[fields_df['Customer Name'] == smartsheet_filtered['Customer Name'].iloc[0]]\n",
    "    pack = utils.smartsheet_len_info(smart_sheet)\n",
    "\n",
    "    \n",
    "    # --------------------------------------------------------------------- Negative Oppty Correction\n",
    "\n",
    "    if (sspt_opp == 'Negative Value') or (st_opp == 'Negative Value'):\n",
    "        print(utils.SSPT_Oppty(renew_filtered))\n",
    "        renew_filtered['Annualized Extended Contract Line List USD Amount'] = renew_filtered['Default Service List Price USD']\n",
    "        renew_filtered.to_csv(f\"{folder_path}/Data/1-Installed Base (2).csv\", index=False)\n",
    "        sspt_opp_value = utils.SSPT_Oppty(renew_filtered)\n",
    "        st_oppty_value = utils.ST_Oppty(renew_filtered)\n",
    "        if sspt_opp == 'Negative Value':\n",
    "            print(bcolors.FAIL + bcolors.BOLD + 'Corrected SSPT oppty values: ' + str(sspt_opp_value)+ bcolors.ENDC)\n",
    "        if st_opp == 'Negative Value':\n",
    "            print(bcolors.FAIL + bcolors.BOLD + 'Corrected ST oppty values: ' + str(st_oppty_value)+ bcolors.ENDC)\n",
    "        sspt_opp = utils.oppty_validation(utils.SSPT_Oppty(renew_filtered))\n",
    "        st_opp = utils.oppty_validation(utils.ST_Oppty(renew_filtered))\n",
    "\n",
    "    \n",
    "    # ---------------------------------------------------------------Filling lists for Q&A dataframe\n",
    "\n",
    "    AC_NAME.append(name)\n",
    "    AC_ID.append(req_id)\n",
    "    IB_VALUE.append(ib_value)\n",
    "    IB_COV.append(ib_covered)\n",
    "    MR.append(mayor_rw)    \n",
    "    EXC.append(exp_care)\n",
    "    SNT.append(sntc_val)    \n",
    "    SSPTOPP.append(sspt_opp)\n",
    "    STOPP.append(st_opp)\n",
    "    SN_LEGHT.append(snl)\n",
    "    ST_L2_LEGHT.append(stl) \n",
    "    PACKAGE_INFO.append(pack)\n",
    "\n",
    "folders_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # --------------------------------------------------------------------- Generating DF needed for Q&A\n",
    "\n",
    "validation_data = pd.DataFrame(columns=['Account Name', 'ID', 'IB Value', 'IB Covered', 'Mayor Renewal', 'SSPT Opportunity', 'ST Opportunity', 'Expert Care validation', 'Smartnet validation'])\n",
    "validation_data['Account Name']=AC_NAME\n",
    "validation_data['ID']=AC_ID\n",
    "validation_data['IB Value']=IB_VALUE\n",
    "validation_data['IB Covered']=IB_COV\n",
    "validation_data['Mayor Renewal']=MR\n",
    "validation_data['SSPT Opportunity']=SSPTOPP\n",
    "validation_data['ST Opportunity']=STOPP\n",
    "validation_data['Expert Care validation']=EXC\n",
    "validation_data['Smartnet validation']=SNT\n",
    "validation_data['Smartnet value lenght'] = SN_LEGHT\n",
    "validation_data['Success_L2 value lenght'] = ST_L2_LEGHT\n",
    "validation_data['Package Info'] = PACKAGE_INFO\n",
    "validation_data['File path'] = folders_path_list\n",
    "\n",
    "\n",
    "validation_data.loc[:,'Account Name':'Package Info'].style.applymap(lambda x: utils.color_qa(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------------------------------------------Oppening defective reports\n",
    "\n",
    "paths = validation_data[(validation_data.loc[:,'IB Value':'Package Info'] != 'Correct').any(1)]['File path'].apply(os.startfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(utils)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tableau Server Automatic Workbook Publishing\n",
    "## Do not use before asking ;)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folders_id = {\n",
    "    \"US COMMERCIAL\": \"fd7772ee-058d-463a-bd0a-4f65542801a4\", # Americas\n",
    "    \"GLOBAL ENTERPRISE SEGMENT\": \"e57405f3-ca6c-4bc2-ad00-6e9e4eaddca3\",\n",
    "    \"LATIN AMERICA\": \"11411241-08ec-488e-b5e5-b858051464a5\",\n",
    "    \"CANADA\": \"2c7d703c-ccd7-4ebb-9a80-493efec42b37\",\n",
    "    \"AMERICAS_SP\": \"001fdd45-0e78-4c94-8529-f541a58903b0\",\n",
    "    \"US PS Market Segment\": \"bc2b9643-6dab-4659-967c-4c7faa1c9fbd\",\n",
    "    \"ANZ AREA\": \"dc644422-3a51-4940-9e0c-5b9eeba4e938\", # APJC\n",
    "    \"ASEAN_AREA\": \"486500cf-bab3-42f2-8cf6-912e0db03056\",\n",
    "    \"GREATER_CHINA\": \"48eaf322-742a-4b72-a750-fe87a18a3e46\",\n",
    "    \"INDIA_AREA\": \"3eda13f8-ce22-40fc-89e1-cca9f69318ee\",\n",
    "    \"JAPAN__\": \"18c5b29f-d451-4546-b924-0f9964d98c95\",\n",
    "    \"ROK_AREA\": \"0f98151c-0030-4f4b-90fc-a785b444cea1\",\n",
    "    \"APJ_SP\": \"517cddf4-032f-4dc0-9569-23ce801ebd33\",\n",
    "    \"EMEAR_GERMANY\": \"d11b1067-045d-42cb-a4c8-67805e4523a4\", # EMEAR\n",
    "    \"EMEAR_SP\": \"35a5ac5e-1654-421e-bb75-d8c95a9408e3\",\n",
    "    \"EMEAR-SOUTH\": \"7e91e72f-18bf-4b3b-8b72-7b964140743b\",\n",
    "    \"EMEAR-NORTH\": \"34b13798-5c47-4bcf-b3d1-917d802d511f\",\n",
    "    \"EMEAR-UKI\": \"268fdf46-d3ee-4623-ace9-97bb32ccc328\",\n",
    "    \"EMEAR_MEA\": \"95dcde09-a6fc-4fb1-b7a8-69e1dc4775e8\",\n",
    "    \"EMEAR-CENTRAL\": \"038970b3-8ea2-4a9a-86e8-6bd470350656\"\n",
    "}\n",
    "\n",
    "fields_df2 = fields_df.copy()\n",
    "fields_df2['folder_id'] = fields_df2['Lvl2 (Region)'].apply(lambda x : folders_id.get(x,''))\n",
    "fields_df2['project_name'] = folders_list\n",
    "fields_df2['project_url'] = fields_df2['project_name'].apply(lambda x: utils.get_url(x))\n",
    "workbook_names = list(fields_df2['project_name'].unique())\n",
    "fields_df2[['Customer Name','Lvl2 (Region)','folder_id','project_name','project_url']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------------------------- Connection with tableau server\n",
    "\n",
    "import os\n",
    "import datetime\n",
    "\n",
    "from tableau_api_lib import TableauServerConnection\n",
    "from tableau_api_lib.utils import querying\n",
    "import time\n",
    "\n",
    "current_path = os.getcwd().replace(\"\\\\\",\"/\")\n",
    "\n",
    "month = datetime.datetime.today().strftime(\"%B\")\n",
    "\n",
    "config = {\n",
    "    \"tableau_server\": {\n",
    "        'server': 'https://cx-tableau-stage.cisco.com',\n",
    "        'api_version': '3.13',\n",
    "        'personal_access_token_name': personal_access_token_name,\n",
    "        'personal_access_token_secret': personal_access_token_secret,\n",
    "        'site_name': 'Compass',\n",
    "        'site_url': 'Compass'\n",
    "    }\n",
    "}\n",
    "\n",
    "conn = TableauServerConnection(config,env='tableau_server')\n",
    "\n",
    "for idx in range(len(fields_df2)):\n",
    "    conn.sign_in()\n",
    "    project = fields_df2['project_name'][idx]\n",
    "    name = fields_df2['Customer Name'][idx]\n",
    "\n",
    "# ----------------------------------------------------------------Publishing reports   \n",
    "\n",
    "    try: \n",
    "\n",
    "        response = conn.publish_workbook(\n",
    "            project_id=fields_df2['folder_id'][idx],\n",
    "            workbook_file_path=f\"{current_path}/OP/{month}/{date}/{project}/{project}.twbx\",\n",
    "            workbook_name=\"{}\".format(project),\n",
    "            workbook_views_to_hide=['QA','Package Info'],\n",
    "            hide_view_flag=True\n",
    "        )\n",
    "\n",
    "        if (response.status_code != 201):    \n",
    "            print(bcolors.FAIL + bcolors.BOLD + \"Estimator has an error and has not been published\"+ bcolors.ENDC)\n",
    "            raise AssertionError()\n",
    "\n",
    "        else : print(f\"The {name} Estimator has been published\")\n",
    "\n",
    "    except Exception as e: \n",
    "        print(bcolors.FAIL + bcolors.BOLD + str(e)+ bcolors.ENDC)\n",
    "        pass\n",
    "\n",
    "    time.sleep(3)\n",
    "    conn.sign_out()\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------------    Q&A of URL's\n",
    "\n",
    "\n",
    "signin={\"credentials\": {\"personalAccessTokenName\": personal_access_token_name, \n",
    "                        \"personalAccessTokenSecret\": personal_access_token_secret,\n",
    "                        \"site\": {\"contentUrl\": \"Compass\"}}}\n",
    "\n",
    "auth = requests.post('https://cx-tableau-stage.cisco.com/api/3.13/auth/signin', headers={'Content-Type' : 'application/json'}, data=json.dumps(signin))\n",
    "auth = ET.fromstring(auth.text)\n",
    "auth_token = auth[0].attrib['token']\n",
    "user_id = auth[0][1].attrib['id']\n",
    "site_id = auth[0][0].attrib['id']\n",
    "\n",
    "print(\"API connected\")\n",
    "\n",
    "workbooks = requests.get(f'https://cx-tableau-stage.cisco.com/api/3.13/sites/{site_id}/workbooks?filter=createdAt:gte:{datetime.datetime.strftime(date,\"%Y-%m-%d\")}T00:00:00Z', headers={'X-Tableau-Auth':auth_token})\n",
    "workbook_parser = ET.fromstring(workbooks.text)\n",
    "\n",
    "published_workbooks = [workbook_parser[1][i].attrib['name'] for i in range(len(workbook_parser[1][:]))]\n",
    "\n",
    "\n",
    "wrong_url = []\n",
    "\n",
    "for workbook in workbook_names:\n",
    "    if workbook not in published_workbooks:\n",
    "        wrong_url.append(workbook)\n",
    "\n",
    "if len(wrong_url)==0:\n",
    "    print('Everything OK')\n",
    "else:\n",
    "    print(bcolors.FAIL + bcolors.BOLD + \"Please review te following reports: \\n\"+ bcolors.ENDC)\n",
    "    print(wrong_url)\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for link in fields_df2['project_url']:\n",
    "    webbrowser.open(link)\n",
    "    print(link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for op_type in type_list:\n",
    "    print(op_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for oppty in sntc_oppty_list:\n",
    "    if oppty == 'N/A':\n",
    "        print(oppty)\n",
    "    else:\n",
    "        print(\"%.1f\" % oppty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "74c2c051579b038b666b8e62878bf13379c44f1dffc0e361bec69b863f87dedd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
