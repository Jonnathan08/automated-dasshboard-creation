{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Get Id's from assigned requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install snowflake-connector-python\n",
    "#!pip install tableauhyperapi\n",
    "#!pip install tableau-api-lib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variables to modify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "auth_path = r\".\\credentials.json\"\n",
    "auth_path = auth_path.replace(\"\\\\\",\"/\")\n",
    "\n",
    "with open(auth_path) as json_file:\n",
    "    json_credentials = json.load(json_file)\n",
    "    json_file.close()\n",
    "\n",
    "user = json_credentials[\"cisco_tableau\"][\"user\"] # Your Cisco e-mail address\n",
    "tableau_template_name = json_credentials[\"paths\"][\"tableau_template_oe_path\"] #twb template name/path\n",
    "ib_file_name = 'IB.csv'\n",
    "coverage_file_name = 'Coverage.csv'\n",
    "sw_file_name = 'SW.csv'\n",
    "sntc_mapping_path = json_credentials[\"paths\"][\"sntc_mapping_path\"]\n",
    "personal_access_token_name = json_credentials[\"cisco_tableau\"][\"access_token_name\"]\n",
    "personal_access_token_secret = json_credentials[\"cisco_tableau\"][\"token\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting the accounts to work on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import datetime\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import shutil\n",
    "import itertools\n",
    "import xml.etree.ElementTree as ET\n",
    "import snowflake.connector\n",
    "import re\n",
    "import webbrowser\n",
    "import importlib\n",
    "import smartsheet_lib as smartsheet\n",
    "import utils_lib as utils\n",
    "import requests\n",
    "import json\n",
    "\n",
    "class bcolors:\n",
    "    HEADER = '\\033[95m'\n",
    "    OKBLUE = '\\033[94m'\n",
    "    OKCYAN = '\\033[96m'\n",
    "    OKGREEN = '\\033[92m'\n",
    "    WARNING = '\\033[93m'\n",
    "    FAIL = '\\033[91m'\n",
    "    ENDC = '\\033[0m'\n",
    "    BOLD = '\\033[1m'\n",
    "    UNDERLINE = '\\033[4m'\n",
    "    \n",
    "current_path = os.getcwd().replace(\"\\\\\",\"/\")\n",
    "\n",
    "date = datetime.datetime.today()\n",
    "date = date.date()\n",
    "\n",
    "if date.weekday() in [0,1]:\n",
    "    delta_t = str(date-datetime.timedelta(4))\n",
    "else:\n",
    "    delta_t = str(date-datetime.timedelta(1))\n",
    "    \n",
    "month = datetime.datetime.today().strftime(\"%B\")\n",
    "\n",
    "print ('Current Path: ' + str(current_path))\n",
    "print ('Current Date: ' + str(date))\n",
    "\n",
    "# -----------------------------------------------------------------\n",
    "\n",
    "\n",
    "smartsheet_client = smartsheet.init_conn(json_credentials[\"smartsheet\"][\"API_access_token\"])\n",
    "#oa_sheet = smartsheet.load_sheet(7190965472520068,client=smartsheet_client,modified_since=delta_t)  #Q3\n",
    "oa_sheet = smartsheet.load_sheet(1763453217073028,client=smartsheet_client,modified_since=delta_t)  #Q4\n",
    "#oa_sheet = smartsheet.load_sheet(3815245262153604,client=smartsheet_client,modified_since=delta_t)  #Q4-2\n",
    "oa_df = pd.DataFrame()\n",
    "sheet_new = smartsheet.get_last_n_rows(oa_sheet,n_rows=4000)\n",
    "oa_df = smartsheet.sheet_to_df2(sheet_new,columns=oa_sheet.columns)\n",
    "oa_df = oa_df.query(\"`Request ID` != ''\")\n",
    "oa_df['Request ID'] = oa_df['Request ID'].apply(lambda x:int(x)) # drop request id decimal places\n",
    "\n",
    "fields_df = utils.get_da_requests(da=user,df=oa_df)\n",
    "fields_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IDs list for CRBO queries (separator must be ';')\n",
    "savs_list,gu_list,cav_list,cr_list = utils.get_ids_list(fields_df,separator=';')\n",
    "cav_names = utils.get_cav_names(user,cav_list.replace(\";\",\",\"))\n",
    "print(f\"SAVs: {savs_list}\")\n",
    "print(f\"GUs: {gu_list}\")\n",
    "print(f\"CAVs: {cav_list}\")\n",
    "\n",
    "print(\"CAV NAMEs:\")\n",
    "for idx in cav_names[\"CAV NAME\"]:\n",
    "    if idx == cav_names[\"CAV NAME\"][len(cav_names[\"CAV NAME\"])-1]:\n",
    "        print(idx)\n",
    "    else:\n",
    "        print(idx,end=\";\")\n",
    "\n",
    "print(f\"CR Parties: {cr_list}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data from Snowflake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IDs list for Snowflake (separator must be ',')\n",
    "savs_list,gu_list,cav_list,cr_list = utils.get_ids_list(fields_df,separator=',')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Telemery dataframe from Snowflake (may take a few minutes)\n",
    "telemetry_df = pd.DataFrame()\n",
    "telemetry_df = utils.get_telemetry_df2(user,savs_list,gu_list,cr_list,cav_list)\n",
    "dna_df = utils.get_dna_df(user,savs_list,gu_list,cr_list,cav_list)\n",
    "print(f\"Telemetry data - Number of rows retrieved: {len(telemetry_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downloading ib data from snowflake\n",
    "ib_df = pd.DataFrame()\n",
    "ib_df_gu = pd.DataFrame()\n",
    "ib_df_cav = pd.DataFrame()\n",
    "ib_df_cr = pd.DataFrame()\n",
    "\n",
    "if 'SAV ID' in fields_df[\"ID TYPE\"].unique():\n",
    "    ib_df = utils.get_ib_data(user=user,ids=savs_list,id_type='SAV')\n",
    "    ib_df.loc[:,'Default Service List Price USD':'Asset List Amount'] = ib_df.loc[:,'Default Service List Price USD':'Asset List Amount'].fillna(0)\n",
    "    ib_df.insert(loc=2, column='Best Site ID', value=-9999)\n",
    "    ib_df.insert(loc=3, column='Best Site Customer Name', value='UNKNOWN')\n",
    "\n",
    "    print(f\"SAV ib data - Number of rows retrieved: {len(ib_df)}\")\n",
    "if 'GU ID' in fields_df[\"ID TYPE\"].unique():\n",
    "    ib_df_gu = utils.get_ib_data(user=user,ids=gu_list,id_type='GU')\n",
    "    ib_df_gu.loc[:,'Default Service List Price USD':'Asset List Amount'] = ib_df_gu.loc[:,'Default Service List Price USD':'Asset List Amount'].fillna(0)\n",
    "    ib_df_gu.insert(loc=2, column='Best Site ID', value=-9999)\n",
    "    ib_df_gu.insert(loc=3, column='Best Site Customer Name', value='UNKNOWN')\n",
    "\n",
    "    print(f\"GU ib data - Number of rows retrieved: {len(ib_df_gu)}\")\n",
    "if 'CAV ID' in fields_df[\"ID TYPE\"].unique():\n",
    "    ib_df_cav = utils.get_ib_data(user=user,ids=cav_list,id_type='CAV')\n",
    "    ib_df_cav.loc[:,'Default Service List Price USD':'Asset List Amount'] = ib_df_cav.loc[:,'Default Service List Price USD':'Asset List Amount'].fillna(0)\n",
    "    ib_df_cav.insert(loc=2, column='Best Site ID', value=-9999)\n",
    "    ib_df_cav.insert(loc=3, column='Best Site Customer Name', value='UNKNOWN')\n",
    "\n",
    "    print(f\"CAV ib data - Number of rows retrieved: {len(ib_df_cav)}\")\n",
    "if 'CR Party ID' in fields_df[\"ID TYPE\"].unique():\n",
    "    ib_df_cr = utils.get_ib_data(user=user,ids=cr_list,id_type='CR')\n",
    "    ib_df_cr.loc[:,'Default Service List Price USD':'Asset List Amount'] = ib_df_cr.loc[:,'Default Service List Price USD':'Asset List Amount'].fillna(0)\n",
    "    ib_df_cr.insert(loc=2, column='Best Site ID', value=-9999)\n",
    "    ib_df_cr.insert(loc=3, column='Best Site Customer Name', value='UNKNOWN')\n",
    "\n",
    "    print(f\"CR ib data - Number of rows retrieved: {len(ib_df_cr)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Downloading coverage data from snowflake\n",
    "\n",
    "coverage_df = pd.DataFrame()\n",
    "coverage_df_gu = pd.DataFrame()\n",
    "coverage_df_cav = pd.DataFrame()\n",
    "coverage_df_cr = pd.DataFrame()\n",
    "\n",
    "if 'SAV ID' in fields_df[\"ID TYPE\"].unique():\n",
    "    coverage_df = utils.get_coverage_data(user=user,ids=savs_list,id_type='SAV')\n",
    "    coverage_df['SAV ID'] = coverage_df['SAV ID'].astype(str)\n",
    "    coverage_df.loc[:,'Item Quantity':'ANNUALIZED_EXTENDED_CONTRACT_LINE_LIST_USD_AMOUNT'] = coverage_df.loc[:,'Item Quantity':'ANNUALIZED_EXTENDED_CONTRACT_LINE_LIST_USD_AMOUNT'].fillna(0)\n",
    "\n",
    "    print(f\"SAV coverage data - Number of rows retrieved: {len(coverage_df)}\")\n",
    "if 'GU ID' in fields_df[\"ID TYPE\"].unique():\n",
    "    coverage_df_gu = utils.get_coverage_data(user=user,ids=gu_list,id_type='GU')\n",
    "    coverage_df_gu['Best Site GU Party ID'] = coverage_df_gu['Best Site GU Party ID'].astype(str)\n",
    "    coverage_df_gu.loc[:,'Item Quantity':'ANNUALIZED_EXTENDED_CONTRACT_LINE_LIST_USD_AMOUNT'] = coverage_df_gu.loc[:,'Item Quantity':'ANNUALIZED_EXTENDED_CONTRACT_LINE_LIST_USD_AMOUNT'].fillna(0)\n",
    "\n",
    "    print(f\"GU coverage data - Number of rows retrieved: {len(coverage_df_gu)}\")\n",
    "if 'CAV ID' in fields_df[\"ID TYPE\"].unique():\n",
    "    coverage_df_cav = utils.get_coverage_data(user=user,ids=cav_list,id_type='CAV')\n",
    "    coverage_df_cav['CAV - Account Name'] = coverage_df_cav['CAV - Account Name'].astype(str)\n",
    "    coverage_df_cav.loc[:,'Item Quantity':'ANNUALIZED_EXTENDED_CONTRACT_LINE_LIST_USD_AMOUNT'] = coverage_df_cav.loc[:,'Item Quantity':'ANNUALIZED_EXTENDED_CONTRACT_LINE_LIST_USD_AMOUNT'].fillna(0)\n",
    "\n",
    "    print(f\"CAV coverage data - Number of rows retrieved: {len(coverage_df_cav)}\")\n",
    "if 'CR Party ID' in fields_df[\"ID TYPE\"].unique():\n",
    "    coverage_df_cr = utils.get_coverage_data(user=user,ids=cr_list,id_type='CR')\n",
    "    coverage_df_cr['Best Site CR Party ID'] = coverage_df_cr['Best Site CR Party ID'].astype(str)\n",
    "    coverage_df_cr.loc[:,'Item Quantity':'ANNUALIZED_EXTENDED_CONTRACT_LINE_LIST_USD_AMOUNT'] = coverage_df_cr.loc[:,'Item Quantity':'ANNUALIZED_EXTENDED_CONTRACT_LINE_LIST_USD_AMOUNT'].fillna(0)\n",
    "\n",
    "    print(f\"CR coverage data - Number of rows retrieved: {len(coverage_df_cr)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TAC dataframe from Snowflake (may take a few minutes)\n",
    "tac_df = pd.DataFrame()\n",
    "tac_df_gu = pd.DataFrame()\n",
    "tac_df_cav = pd.DataFrame()\n",
    "tac_df_cr = pd.DataFrame()\n",
    "\n",
    "if 'SAV ID' in fields_df[\"ID TYPE\"].unique():\n",
    "    tac_df = utils.get_tac_df_new(user=user,ids=savs_list,id_type='SAV ID')\n",
    "    tac_df[\"BUG_CNT\"] = tac_df[\"BUG_CNT\"].replace(\"\",0.0)\n",
    "    print(f\"SAV TAC data - Number of rows retrieved: {len(tac_df)}\")\n",
    "if 'GU ID' in fields_df[\"ID TYPE\"].unique():\n",
    "    tac_df_gu = utils.get_tac_df_new(user=user,ids=gu_list,id_type='GU ID')\n",
    "    tac_df_gu[\"BUG_CNT\"] = tac_df_gu[\"BUG_CNT\"].replace(\"\",0.0)\n",
    "    print(f\"GU TAC data - Number of rows retrieved: {len(tac_df_gu)}\")\n",
    "if 'CAV ID' in fields_df[\"ID TYPE\"].unique():\n",
    "    tac_df_cav = utils.get_tac_df_new(user=user,ids=cav_list,id_type='CAV ID')\n",
    "    tac_df_cav[\"BUG_CNT\"] = tac_df_cav[\"BUG_CNT\"].replace(\"\",0.0)\n",
    "    print(f\"CAV TAC data - Number of rows retrieved: {len(tac_df_cav)}\")\n",
    "if 'CR Party ID' in fields_df[\"ID TYPE\"].unique():\n",
    "    tac_df_cr = utils.get_tac_df_new(user=user,ids=cr_list,id_type='PARTY ID')\n",
    "    tac_df_cr[\"BUG_CNT\"] = tac_df_cr[\"BUG_CNT\"].replace(\"\",0.0)\n",
    "    print(f\"CR TAC data - Number of rows retrieved: {len(tac_df_cr)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Package creation\n",
    "\n",
    "#### Note: Run the following lines only if you have already downloaded the data from CRBO and saved it in their respective SAV_ID/GU_ID folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------- Mapping Files\n",
    "\n",
    "local_path = \".\"\n",
    "\n",
    "contract_types_list = pd.read_excel(f\"{local_path}/Mapping files/1-Contract_Types_List.xlsx\", sheet_name='SNTCSolutionSupport')\n",
    "contract_types_list = contract_types_list.astype({'Contract Type':str},errors='raise')\n",
    "\n",
    "success_track_pricing_list = pd.read_excel(f\"{local_path}/Mapping files/2-Success_Track_Pricing_List.xlsx\", sheet_name='Success Track PIDs')\n",
    "success_track_pricing_list = success_track_pricing_list.astype({'Product SKU':str},errors='raise')\n",
    "\n",
    "sspt_pricing_list_eligibleSSPT = pd.read_excel(f\"{local_path}/Mapping files/3-SSPT_Princing_List.xlsx\", sheet_name='Eligible SSPT')\n",
    "sspt_pricing_list_eligibleSSPT = sspt_pricing_list_eligibleSSPT.astype({'Product SKU':str},errors='raise')\n",
    "\n",
    "sspt_pricing_list_outputTable = pd.read_excel(f\"{local_path}/Mapping files/3-SSPT_Princing_List.xlsx\", sheet_name='Output Table')\n",
    "sspt_pricing_list_outputTable = sspt_pricing_list_outputTable.astype({'Product SKU':str},errors='raise')\n",
    "\n",
    "sntc_pricing_list = pd.read_excel(f\"{local_path}/Mapping files/4-SNTC_Princing_List.xlsx\", sheet_name='Output')\n",
    "sntc_pricing_list = sntc_pricing_list.astype({'Product SKU ':str},errors='raise')\n",
    "\n",
    "combined_services = pd.read_excel(f\"{local_path}/Mapping files/8-Combined_Services.xlsx\", sheet_name='Sheet1')\n",
    "combined_services = combined_services.astype({'Combined Services Service Level':str},errors='raise')\n",
    "\n",
    "product_banding = pd.read_excel(f\"{local_path}/Mapping files/9-PRODUCT_BANDING.xlsx\", sheet_name='9-PRODUCT_BANDING')\n",
    "product_banding = product_banding.astype({'INTERNAL_BE_PRODUCT_FAMILY':str},errors='raise')\n",
    "\n",
    "expert_care_component_bands = pd.read_excel(f\"{local_path}/Mapping files/7-Expert_Care_Components_Bands.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# -------------------------------------------------------- Package Creation ------\n",
    "smartsheet_fields = ['index','Request ID','Date Created',\n",
    "                         'Assigned DA','Campaign Name','Customer Name',\n",
    "                         'Input file URL','ID TYPE','SAV ID','CAV ID',\n",
    "                         'CAV BU ID','GU ID','Lvl1','Lvl2 (Region)',\n",
    "                         'Contract ID','Inventory Name','Appliance ID',\n",
    "                         'CR Party Name','CR Party ID','Comments','DA Comments',\n",
    "                         'Status','Requester Name','Who should be notified on completion of Analysis',\n",
    "                         'OP Status']\n",
    "folders_list = []\n",
    "folders_path_list = []\n",
    "type_list = []\n",
    "sntc_oppty_list = []\n",
    "renewals = pd.DataFrame()\n",
    "coverage = pd.DataFrame()\n",
    "subs = pd.DataFrame()\n",
    "map_req_type = {'SAV ID':'SAV','GU ID':'GU','CR Party ID':'CR','CAV ID':'CAV'}\n",
    "\n",
    "# ------------------------------------------------------------------- Lists for Q&A\n",
    "AC_NAME=[]\n",
    "AC_ID=[]\n",
    "IB_VALUE=[]\n",
    "IB_COV=[]\n",
    "MR=[]\n",
    "SSPTOPP=[]\n",
    "STOPP=[]\n",
    "EXC=[]\n",
    "SNT=[]\n",
    "SN_LEGHT = []\n",
    "ST_L2_LEGHT=[]\n",
    "PACKAGE_INFO=[]\n",
    "\n",
    "# ------------------------------------------------------------------- Accounts loop\n",
    "    \n",
    "for idx in range(len(fields_df)):\n",
    "    req_type = fields_df['ID TYPE'][idx]\n",
    "    name = re.sub('[^A-Za-z0-9\\-]+', '', fields_df['Customer Name'][idx][0:15])\n",
    "    theater = fields_df['Lvl1'][idx]\n",
    "    party_ids = fields_df['cr_list'][idx]\n",
    "    print(name)\n",
    "    \n",
    "    if req_type == 'SAV ID':\n",
    "        ids = fields_df['sav_list'][idx]\n",
    "        ids_smartsheet = [fields_df['SAV ID'][idx]]\n",
    "        ids_smartsheet2 = ids\n",
    "        print(ids)\n",
    "        id_field = 'SAV ID'\n",
    "        id_field_sw = 'SAV ID'\n",
    "        id_flag_tac = 'SAV'\n",
    "        renewals = ib_df.copy()\n",
    "        coverage = coverage_df.copy()\n",
    "        tac = tac_df.copy()\n",
    "        id_field_tac = 'ID'\n",
    "        \n",
    "    elif req_type == 'GU ID':\n",
    "        ids = fields_df['gu_list'][idx]\n",
    "        ids_smartsheet = [fields_df['GU ID'][idx]]\n",
    "        ids_smartsheet2 = ids\n",
    "        print(ids)\n",
    "        id_field = 'Best Site GU Party ID'\n",
    "        id_field_sw = 'GU Party ID'\n",
    "        id_flag_tac = 'GU'\n",
    "        renewals = ib_df_gu.copy()\n",
    "        coverage = coverage_df_gu.copy()\n",
    "        tac = tac_df_gu.copy()\n",
    "        id_field_tac = 'ID'\n",
    "        \n",
    "    elif req_type == 'CAV ID':\n",
    "        #cav_names[\"CAV ID\"] = cav_names[\"CAV ID\"].astype(str)\n",
    "        #cav_name_id = pd.DataFrame(data = {\"CAV ID\":fields_df[[\"cav_list\"]].iloc[idx,0]}).merge(cav_names,how=\"inner\")[\"CAV NAME\"].to_list()\n",
    "        #ids = cav_name_id\n",
    "        ids_smartsheet = [fields_df[\"CAV ID\"][idx]]\n",
    "        ids_smartsheet2 = fields_df['cav_list'][idx]\n",
    "        print(ids)\n",
    "        id_field = 'CAV - Account Name'\n",
    "        id_field_sw = 'CAV -  Account Name'\n",
    "        id_flag_tac = 'CAV'\n",
    "        renewals = ib_df_cav.copy()\n",
    "        coverage = coverage_df_cav.copy()\n",
    "        tac = tac_df_cav.copy()\n",
    "        id_field_tac = 'ID'\n",
    "        \n",
    "    elif req_type == 'CR Party ID':\n",
    "        ids = fields_df['cr_list'][idx]\n",
    "        ids_smartsheet = [fields_df['CR Party ID'][idx]]\n",
    "        ids_smartsheet2 = ids\n",
    "        print(ids)\n",
    "        id_field = 'Best Site CR Party ID'\n",
    "        id_field_sw = 'CR Party ID'\n",
    "        id_flag_tac = 'GU'\n",
    "        renewals = ib_df_cr.copy()\n",
    "        coverage = coverage_df_cr.copy()\n",
    "        tac = tac_df_cr.copy()\n",
    "        id_field_tac = 'PARTY ID'\n",
    "    \n",
    "    if req_type == \"CAV ID\":\n",
    "        req_id = fields_df['CAV ID'][idx][0:6]\n",
    "    else:\n",
    "        req_id = ids[0]\n",
    "    \n",
    "    # ---------------------------------------------------------------------- Folders creation\n",
    "\n",
    "    folder =  f\"OP_{theater}_{req_type}_{req_id}_{name}_{str(date.year)}_{str(date.month)}_{str(date.day)}\" # folder name\n",
    "    folder_path = f\"{current_path}/OP/{month}/{date}/{folder}\"\n",
    "    \n",
    "    try:\n",
    "        os.makedirs(f\"{folder_path}/Data\")\n",
    "        os.makedirs(f\"{folder_path}/Extracts\")\n",
    "        \n",
    "    except: pass    \n",
    "    \n",
    "    folders_list.append(folder)\n",
    "    folders_path_list.append(f'{folder_path}/{folder}.twb')\n",
    "    \n",
    "    # --------------------------------------------------------------------- Data transform and filtering\n",
    "    \n",
    "    smartsheet_filtered = fields_df[smartsheet_fields].iloc[[idx]]\n",
    "    smartsheet_filtered = smartsheet_filtered.rename(columns={\"Who should be notified on completion of Analysis\":\"Parties Active Collectors\"})\n",
    "    renew_filtered = renewals.query(\"`{}` in {}\".format(id_field,ids))\n",
    "    coverage_filtered  = coverage.query(\"`{}` in {}\".format(id_field,ids))      \n",
    "        \n",
    "    dna_filtered = dna_df[dna_df['CUSTOMER_ID'].isin([int(ids) for ids in ids_smartsheet2])]\n",
    "    dna_filtered = dna_filtered[dna_filtered['ACCOUNT_INDENTIFIER']==map_req_type.get(req_type)]\n",
    "    \n",
    "    telemetry_filtered = telemetry_df[telemetry_df['ID'].isin([int(ids) for ids in ids_smartsheet2])]\n",
    "    telemetry_filtered = telemetry_filtered[telemetry_filtered['ACCOUNT_ID']==map_req_type.get(req_type)]\n",
    "    parties_active_collectors = telemetry_filtered[\"Party ID\"].unique().astype(str).tolist()\n",
    "    parties_active_collectors = \",\".join(parties_active_collectors)                                         \n",
    "    \n",
    "    smartsheet_filtered[\"Parties Active Collectors\"][idx] = parties_active_collectors\n",
    "\n",
    "    if req_type == 'CAV ID':\n",
    "        ids = fields_df['cav_list'][idx]\n",
    "    \n",
    "    tac_filtered = tac.query(\"(`{}` in {}) and (FLAG == '{}')\".format(id_field_tac,[int(i) for i in ids],id_flag_tac)) # id in TAC must be integer, not str\n",
    "        \n",
    "    print(len(renew_filtered))\n",
    "    \n",
    "    dna_filtered.to_csv(f\"{folder_path}/Data/DNA.csv\",index=False)\n",
    "        \n",
    "    renew_filtered = utils.fill_nas(renew_filtered)\n",
    "    coverage_filtered = utils.fill_nas(coverage_filtered)\n",
    "\n",
    "    if req_type == 'SAV ID':\n",
    "        renew_filtered[['SAV ID','LDoS FY','Instance Shipped Fiscal Year','Contract Number']] = renew_filtered[['SAV ID','LDoS FY','Instance Shipped Fiscal Year','Contract Number']].fillna(0).apply(pd.to_numeric, downcast='integer')\n",
    "    elif req_type == 'GU ID':\n",
    "        renew_filtered[['Best Site GU Party ID','LDoS FY','Instance Shipped Fiscal Year','Contract Number']] = renew_filtered[['Best Site GU Party ID','LDoS FY','Instance Shipped Fiscal Year','Contract Number']].fillna(0).apply(pd.to_numeric, downcast='integer')\n",
    "    elif req_type == 'CAV ID':\n",
    "        renew_filtered[['CAV ID','LDoS FY','Instance Shipped Fiscal Year','Contract Number']] = renew_filtered[['CAV ID','LDoS FY','Instance Shipped Fiscal Year','Contract Number']].fillna(0).apply(pd.to_numeric, downcast='integer')\n",
    "    elif req_type == 'CR Party ID':\n",
    "        renew_filtered[['Best Site CR Party ID','LDoS FY','Instance Shipped Fiscal Year','Contract Number']] = renew_filtered[['Best Site CR Party ID','LDoS FY','Instance Shipped Fiscal Year','Contract Number']].fillna(0).apply(pd.to_numeric, downcast='integer')\n",
    "   \n",
    "    renew_filtered['LDoS'] = pd.to_datetime(renew_filtered['LDoS'], errors='coerce').replace({pd.NaT:None})\n",
    "    renew_filtered['Item Quantity'] = renew_filtered['Item Quantity'].astype(float)\n",
    "    coverage_filtered['Item Quantity'] = coverage_filtered['Item Quantity'].astype(int)\n",
    "    \n",
    "    # --------------------------------------------------------------------- Template xml set up\n",
    "\n",
    "    tree = ET.parse(tableau_template_name)\n",
    "    \n",
    "    for extract_path in tree.getroot().findall(\"./datasources/datasource/connection/named-connections/named-connection/connection[@class='textscan']\"):\n",
    "        extract_path.attrib['directory'] = f\"{folder_path}/Data\"\n",
    "    \n",
    "    for extract_path in tree.getroot().findall(\"./datasources/datasource/connection/named-connections/named-connection/connection[@class='hyper']\"):\n",
    "        extract_name = extract_path.attrib['dbname'].split('/')[-1]\n",
    "        extract_path.attrib['dbname'] = f\"{folder_path}/Extracts/{extract_name}\"\n",
    "    \n",
    "    with open (f\"{folder_path}/{folder}.twb\", \"wb\") as files :                                             \n",
    "        tree.write(files)\n",
    "        \n",
    "    # --------------------------------------------------------------------- Package type\n",
    "        \n",
    "    if len(renew_filtered) > 0:\n",
    "        if len(telemetry_filtered) == 0:\n",
    "            type_list.append('Lite')\n",
    "        else:\n",
    "            type_list.append('Prime')\n",
    "    elif len(renew_filtered) == 0:\n",
    "        type_list.append('No Report')\n",
    "    \n",
    "    # --------------------------------------------------------------------- Extracts creation\n",
    "\n",
    "    utils.create_extract(name='Smartsheet',columns=utils.get_schema(table='smartsheet',id_type=req_type),df=smartsheet_filtered,path=folder_path)\n",
    "\n",
    "\n",
    "    # --------------------------------------------------------------------- CSV creation for Tableau\n",
    "    ### ---------------------------------------  Install Base merge \n",
    "\n",
    "    renew_filtered = utils.set_datasource(renew_filtered,'ib',f\"{folder_path}/Data/1-Installed Base (2).csv\"\n",
    "                    ,contract_types_list,\n",
    "                    success_track_pricing_list,sspt_pricing_list_eligibleSSPT,\n",
    "                    sspt_pricing_list_outputTable,sntc_pricing_list,product_banding)\n",
    "\n",
    "    ### ---------------------------------------  SNTC Collector\n",
    "    telemetry_filtered = utils.set_datasource(telemetry_filtered,'cir',f\"{folder_path}/Data/3-SNTC Collector (2).csv\",\n",
    "                    contract_types_list,\n",
    "                    success_track_pricing_list,sspt_pricing_list_eligibleSSPT,\n",
    "                    sspt_pricing_list_outputTable,sntc_pricing_list,product_banding)\n",
    "\n",
    "    ### ---------------------------------------  Coverage\n",
    "    coverage_filtered = utils.set_datasource(coverage_filtered,'coverage',f\"{folder_path}/Data/Coverage.csv\",\n",
    "                    contract_types_list,\n",
    "                    success_track_pricing_list,sspt_pricing_list_eligibleSSPT,\n",
    "                    sspt_pricing_list_outputTable,sntc_pricing_list,product_banding)\n",
    "\n",
    "    ### ---------------------------------------  TAC\n",
    "    tac_filtered = utils.set_datasource(tac_filtered,'tac',f\"{folder_path}/Data/6-TAC.csv\",\n",
    "                    contract_types_list,\n",
    "                    success_track_pricing_list,sspt_pricing_list_eligibleSSPT,\n",
    "                    sspt_pricing_list_outputTable,sntc_pricing_list,product_banding)\n",
    "\n",
    "    ## ---------------------------------------  Expert Care\n",
    "\n",
    "    expert_care_component_bands.to_csv(f\"{folder_path}/Data/7-Expert_Care_Components_Bands.csv\", index=False)\n",
    "\n",
    "    # --------------------------------------------------------------------- Calculating Q&A values\n",
    "\n",
    "    ib_value = utils.ib_value_validation(utils.IB_attributes(renew_filtered))\n",
    "    ib_covered = utils.ib_covered_validation(utils.IB_attributes(renew_filtered))\n",
    "    mayor_rw = utils.rw_validation(utils.IB_attributes(renew_filtered))\n",
    "    sspt_opp = utils.oppty_validation(utils.SSPT_Oppty(renew_filtered))\n",
    "    st_opp = utils.oppty_validation(utils.ST_Oppty(renew_filtered))\n",
    "    exp_care = utils.oppty_validation(utils.expert_care_verification(expert_care_component_bands))\n",
    "    sntc_val = utils.oppty_validation(utils.smartnet_verification(renew_filtered))\n",
    "    snl = utils.lenght_validation(utils.smartnet_total_care_NBD_list_price(renew_filtered)[1])\n",
    "    stl = utils.lenght_validation(utils.estimated_list_price(renew_filtered)[1])\n",
    "    smart_sheet = fields_df[fields_df['Customer Name'] == smartsheet_filtered['Customer Name'].iloc[0]]\n",
    "    pack = utils.smartsheet_len_info(smart_sheet)\n",
    "\n",
    "    # --------------------------------------------------------------------- Negative Oppty Correction\n",
    "\n",
    "    if (sspt_opp == 'Negative Value') or (st_opp == 'Negative Value'):\n",
    "        print(utils.SSPT_Oppty(renew_filtered))\n",
    "        renew_filtered['Annualized Extended Contract Line List USD Amount'] = renew_filtered['Default Service List Price USD']\n",
    "        renew_filtered.to_csv(f\"{folder_path}/Data/1-Installed Base (2).csv\", index=False)\n",
    "        sspt_opp_value = utils.SSPT_Oppty(renew_filtered)\n",
    "        st_oppty_value = utils.ST_Oppty(renew_filtered)\n",
    "\n",
    "        if sspt_opp == 'Negative Value':\n",
    "            print(bcolors.FAIL + bcolors.BOLD + 'Corrected SSPT oppty values: ' + str(sspt_opp_value)+ bcolors.ENDC)\n",
    "        if st_opp == 'Negative Value':\n",
    "            print(bcolors.FAIL + bcolors.BOLD + 'Corrected ST oppty values: ' + str(st_oppty_value)+ bcolors.ENDC)\n",
    "        sspt_opp = utils.oppty_validation(utils.SSPT_Oppty(renew_filtered))\n",
    "        st_opp = utils.oppty_validation(utils.ST_Oppty(renew_filtered))\n",
    "\n",
    "    \n",
    "    # ---------------------------------------------------------------Filling lists for Q&A dataframe\n",
    "\n",
    "    AC_NAME.append(name)\n",
    "    AC_ID.append(req_id)\n",
    "    IB_VALUE.append(ib_value)\n",
    "    IB_COV.append(ib_covered)\n",
    "    MR.append(mayor_rw)    \n",
    "    EXC.append(exp_care)\n",
    "    SNT.append(sntc_val)    \n",
    "    SSPTOPP.append(sspt_opp)\n",
    "    STOPP.append(st_opp)\n",
    "    SN_LEGHT.append(snl)\n",
    "    ST_L2_LEGHT.append(stl) \n",
    "    PACKAGE_INFO.append(pack)\n",
    "\n",
    "folders_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # --------------------------------------------------------------------- Generating DF needed for Q&A\n",
    "\n",
    "validation_data = pd.DataFrame(columns=['Account Name', 'ID', 'IB Value', 'IB Covered', 'Mayor Renewal', 'SSPT Opportunity', 'ST Opportunity', 'Expert Care validation', 'Smartnet validation'])\n",
    "validation_data['Account Name']=AC_NAME\n",
    "validation_data['ID']=AC_ID\n",
    "validation_data['IB Value']=IB_VALUE\n",
    "validation_data['IB Covered']=IB_COV\n",
    "validation_data['Mayor Renewal']=MR\n",
    "validation_data['SSPT Opportunity']=SSPTOPP\n",
    "validation_data['ST Opportunity']=STOPP\n",
    "validation_data['Expert Care validation']=EXC\n",
    "validation_data['Smartnet validation']=SNT\n",
    "validation_data['Smartnet value lenght'] = SN_LEGHT\n",
    "validation_data['Success_L2 value lenght'] = ST_L2_LEGHT\n",
    "validation_data['Package Info'] = PACKAGE_INFO\n",
    "validation_data['File path'] = folders_path_list\n",
    "\n",
    "\n",
    "validation_data.loc[:,'Account Name':'Package Info'].style.applymap(lambda x: utils.color_qa(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------------------------------------------Oppening defective reports\n",
    "\n",
    "paths = validation_data[(validation_data.loc[:,'IB Value':'Package Info'] != 'Correct').any(1)]['File path'].apply(os.startfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(utils)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tableau Server Automatic Workbook Publishing\n",
    "## Do not use before asking ;)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folders_id = {\n",
    "    \"US COMMERCIAL\": \"fd7772ee-058d-463a-bd0a-4f65542801a4\", # Americas\n",
    "    \"GLOBAL ENTERPRISE SEGMENT\": \"e57405f3-ca6c-4bc2-ad00-6e9e4eaddca3\",\n",
    "    \"LATIN AMERICA\": \"11411241-08ec-488e-b5e5-b858051464a5\",\n",
    "    \"CANADA\": \"2c7d703c-ccd7-4ebb-9a80-493efec42b37\",\n",
    "    \"AMERICAS_SP\": \"001fdd45-0e78-4c94-8529-f541a58903b0\",\n",
    "    \"US PS Market Segment\": \"bc2b9643-6dab-4659-967c-4c7faa1c9fbd\",\n",
    "    \"ANZ AREA\": \"dc644422-3a51-4940-9e0c-5b9eeba4e938\", # APJC\n",
    "    \"ASEAN_AREA\": \"486500cf-bab3-42f2-8cf6-912e0db03056\",\n",
    "    \"GREATER_CHINA\": \"48eaf322-742a-4b72-a750-fe87a18a3e46\",\n",
    "    \"INDIA_AREA\": \"3eda13f8-ce22-40fc-89e1-cca9f69318ee\",\n",
    "    \"JAPAN__\": \"18c5b29f-d451-4546-b924-0f9964d98c95\",\n",
    "    \"ROK_AREA\": \"0f98151c-0030-4f4b-90fc-a785b444cea1\",\n",
    "    \"APJ_SP\": \"517cddf4-032f-4dc0-9569-23ce801ebd33\",\n",
    "    \"EMEAR_GERMANY\": \"d11b1067-045d-42cb-a4c8-67805e4523a4\", # EMEAR\n",
    "    \"EMEAR_SP\": \"35a5ac5e-1654-421e-bb75-d8c95a9408e3\",\n",
    "    \"EMEAR-SOUTH\": \"7e91e72f-18bf-4b3b-8b72-7b964140743b\",\n",
    "    \"EMEAR-NORTH\": \"34b13798-5c47-4bcf-b3d1-917d802d511f\",\n",
    "    \"EMEAR-UKI\": \"268fdf46-d3ee-4623-ace9-97bb32ccc328\",\n",
    "    \"EMEAR_MEA\": \"95dcde09-a6fc-4fb1-b7a8-69e1dc4775e8\",\n",
    "    \"EMEAR-CENTRAL\": \"038970b3-8ea2-4a9a-86e8-6bd470350656\"\n",
    "}\n",
    "\n",
    "fields_df2 = fields_df.copy()\n",
    "fields_df2['folder_id'] = fields_df2['Lvl2 (Region)'].apply(lambda x : folders_id.get(x,''))\n",
    "fields_df2['project_name'] = folders_list\n",
    "fields_df2['project_url'] = fields_df2['project_name'].apply(lambda x: utils.get_url(x))\n",
    "workbook_names = list(fields_df2['project_name'].unique())\n",
    "fields_df2[['Customer Name','Lvl2 (Region)','folder_id','project_name','project_url']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------------------------- Connection with tableau server\n",
    "\n",
    "import os\n",
    "import datetime\n",
    "from tableau_api_lib import TableauServerConnection\n",
    "from tableau_api_lib.utils import querying\n",
    "import time\n",
    "import json\n",
    "\n",
    "current_path = os.getcwd().replace(\"\\\\\",\"/\")\n",
    "\n",
    "month = datetime.datetime.today().strftime(\"%B\")\n",
    "\n",
    "config = {\n",
    "    \"tableau_server\": {\n",
    "        'server': 'https://cx-tableau-stage.cisco.com',\n",
    "        'api_version': '3.13',\n",
    "        'personal_access_token_name': personal_access_token_name,\n",
    "        'personal_access_token_secret': personal_access_token_secret,\n",
    "        'site_name': 'Compass',\n",
    "        'site_url': 'Compass'\n",
    "    }\n",
    "}\n",
    "\n",
    "conn = TableauServerConnection(config,env='tableau_server')\n",
    "\n",
    "for idx in range(len(fields_df2)):\n",
    "    conn.sign_in()\n",
    "    project = fields_df2['project_name'][idx]\n",
    "    name = fields_df2['Customer Name'][idx]\n",
    "\n",
    "# ----------------------------------------------------------------Publishing reports   \n",
    "\n",
    "    try: \n",
    "\n",
    "        response = conn.publish_workbook(\n",
    "            project_id=fields_df2['folder_id'][idx],\n",
    "            workbook_file_path=f\"{current_path}/OP/{month}/{date}/{project}/{project}.twbx\",\n",
    "            workbook_name=\"{}\".format(project),\n",
    "            workbook_views_to_hide=['QA','Package Info'],\n",
    "            hide_view_flag=True\n",
    "        )\n",
    "\n",
    "        if (response.status_code != 201):    \n",
    "            print(bcolors.FAIL + bcolors.BOLD + \"Estimator has an error and has not been published\"+ bcolors.ENDC)\n",
    "            raise AssertionError()\n",
    "\n",
    "        else : print(f\"The {name} Estimator has been published\")\n",
    "\n",
    "    except Exception as e: \n",
    "        print(bcolors.FAIL + bcolors.BOLD + str(e)+ bcolors.ENDC)\n",
    "        pass\n",
    "\n",
    "    time.sleep(3)\n",
    "    conn.sign_out()\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------------    Q&A of URL's\n",
    "\n",
    "\n",
    "signin={\"credentials\": {\"personalAccessTokenName\": personal_access_token_name, \n",
    "                        \"personalAccessTokenSecret\": personal_access_token_secret,\n",
    "                        \"site\": {\"contentUrl\": \"Compass\"}}}\n",
    "\n",
    "auth = requests.post('https://cx-tableau-stage.cisco.com/api/3.13/auth/signin', headers={'Content-Type' : 'application/json'}, data=json.dumps(signin))\n",
    "auth = ET.fromstring(auth.text)\n",
    "auth_token = auth[0].attrib['token']\n",
    "user_id = auth[0][1].attrib['id']\n",
    "site_id = auth[0][0].attrib['id']\n",
    "\n",
    "print(\"API connected\")\n",
    "\n",
    "workbooks = requests.get(f'https://cx-tableau-stage.cisco.com/api/3.13/sites/{site_id}/workbooks?filter=createdAt:gte:{datetime.datetime.strftime(date,\"%Y-%m-%d\")}T00:00:00Z', headers={'X-Tableau-Auth':auth_token})\n",
    "workbook_parser = ET.fromstring(workbooks.text)\n",
    "\n",
    "published_workbooks = [workbook_parser[1][i].attrib['name'] for i in range(len(workbook_parser[1][:]))]\n",
    "\n",
    "\n",
    "wrong_url = []\n",
    "\n",
    "for workbook in workbook_names:\n",
    "    if workbook not in published_workbooks:\n",
    "        wrong_url.append(workbook)\n",
    "\n",
    "if len(wrong_url)==0:\n",
    "    print('Everything OK')\n",
    "else:\n",
    "    print(bcolors.FAIL + bcolors.BOLD + \"Please review te following reports: \\n\"+ bcolors.ENDC)\n",
    "    print(wrong_url)\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for link in fields_df2['project_url']:\n",
    "    webbrowser.open(link)\n",
    "    print(link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for op_type in type_list:\n",
    "    print(op_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for oppty in sntc_oppty_list:\n",
    "    if oppty == 'N/A':\n",
    "        print(oppty)\n",
    "    else:\n",
    "        print(\"%.1f\" % oppty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "result = pd.read_excel(r\"C:\\Users\\nedelgad\\OneDrive - Nub78\\OE Automation\\Snoflake\\Test 3\\result.xlsx\", sheet_name='result')\n",
    "ib_data = pd.read_excel(r\"C:\\Users\\nedelgad\\OneDrive - Nub78\\OE Automation\\Snoflake\\Test 3\\result.xlsx\", sheet_name='1-Installed Base (2)')\n",
    "ib_data.rename(columns={ib_data.columns[0]:'customer_id'}, inplace=True)\n",
    "result.rename(columns={result.columns[0]:'customer_id'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ib_data_copy = ib_data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ib_data_copy.drop(columns=['Best Site ID',\n",
    "                            'Best Site Customer Name',\n",
    "                            'SWSS Flag',\n",
    "                            'Product SKU',\n",
    "                            'Product SKU ',\n",
    "                            'Product SKU (Eligible SSPT)',\n",
    "                            'Product SKU (Output Table)',\n",
    "                            'L12HR',\n",
    "                            'ELSUS','SSPTS',\n",
    "                        'SSS2P','SSTCM','SSSW',\"3SNTP (Output)\",'GSP','SWSS 2.0 Category* ','GSP (HTEC)','Combined Services Service Level','INTERNAL_BE_PRODUCT_FAMILY','EDW_CREATE_DTM',\n",
    "                        'EDW_CREATE_USER','EDW_UPDATE_DTM','EDW_UPDATE_USER'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ib_data_copy.columns = result.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, row in result.iterrows():\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "188894ff957ed4c0bf1016ca99119c7aaf4eed608afb84d6dc1d383d4e0186dd"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "87e43e869ebd2c3b1150c2f8834dddb6350409738d96eb8dc26b716e47c2cdf7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
